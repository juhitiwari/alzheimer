{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import glob\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_control = '../data/Pitt/Control/cookie/*.cha'\n",
    "path_dementia = '../data/Pitt/Dementia/cookie/*.cha'\n",
    "\n",
    "files_control = sorted(glob.glob(path_control))\n",
    "files_dementia = sorted(glob.glob(path_dementia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_participant_from_file(file):\n",
    "    par_re = re.compile(r'^\\*PAR:\\s(.*)')\n",
    "    cont_re = re.compile(r'^\\t(.*)')\n",
    "    \n",
    "    document = open(file).read()\n",
    "    doc = document.split('\\n')    \n",
    "\n",
    "    pre_list = []\n",
    "    in_par = False\n",
    "    for line in doc:\n",
    "        pattern = cont_re if in_par else par_re\n",
    "        match = pattern.match(line)\n",
    "        if match:\n",
    "            utterance = match.group(1)\n",
    "            utterance = re.sub('\\\\x15.*\\\\x15$', '', utterance)\n",
    "            pre_list.append(utterance)\n",
    "            \n",
    "            in_par = True\n",
    "        else:\n",
    "            in_par = False\n",
    "            \n",
    "    return(pre_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_symbol_control = [extract_participant_from_file(f) for f in files_control]\n",
    "utterances_symbol_dementia = [extract_participant_from_file(f) for f in files_dementia]\n",
    "\n",
    "control_df = pd.DataFrame(\n",
    "    {'label': 0,   # Control = 0\n",
    "     'sentence': utterances_symbol_control\n",
    "     })\n",
    "\n",
    "dementia_df = pd.DataFrame(\n",
    "    {'label': 1,    # Dementia = 1\n",
    "     'sentence': utterances_symbol_dementia\n",
    "     })\n",
    "\n",
    "# Create shuffled dataframes\n",
    "df_temp = pd.concat([control_df, dementia_df])\n",
    "df_temp = shuffle(df_temp).reset_index(drop=True)\n",
    "df_temp['text'] = df_temp.apply(lambda row: ' '.join(row.sentence), axis=1)\n",
    "\n",
    "df = df_temp.copy()\n",
    "#df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagged_dialogue(dialogue):\n",
    "    tagged = [(token.text, token.pos_) for token in nlp(dialogue)]  # To get tag and dep labels, replace pos_ by tag_ and dep_. See spacy documentation for meanings.\n",
    "    tagged_temp = [' '.join(j) for j in tagged]\n",
    "    tagged_final = ' '.join(tagged_temp)\n",
    "    return(tagged_final)\n",
    "\n",
    "df['pos_text'] = df.apply(lambda x: tagged_dialogue(x['text']), axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_tags(dialogue):\n",
    "    tagged = [(token.text, token.pos_) for token in nlp(dialogue)]\n",
    "    tagged_temp = [i[1] for i in tagged]\n",
    "    tag_final = ' '.join(tagged_temp)\n",
    "    return(tag_final)\n",
    "\n",
    "df['pos_'] = df.apply(lambda x: only_tags(x['text']), axis = 1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace abbreviations with full words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = { \"ADJ\":\"adjective\",\n",
    "\"ADP\":\"adposition\",\n",
    "\"ADV\":\"adverb\",\n",
    "\"AUX\":\"auxiliary\",\n",
    "\"CONJ\":\"conjunction\",\n",
    "\"CCONJ\":\"coordinating conjunction\",\n",
    "\"DET\":\"determiner\",\n",
    "\"INTJ\":\"interjection\",\n",
    "\"NOUN\":\"noun\",\n",
    "\"NUM\":\"numeral\",\n",
    "\"PART\":\"particle\",\n",
    "\"PRON\":\"pronoun\",\n",
    "\"PROPN\":\"proper noun\",\n",
    "\"PUNCT\":\"punctuation\",\n",
    "\"SCONJ\":\"subordinating conjunction\",\n",
    "\"SYM\":\"symbol\",\n",
    "\"VERB\":\"verb\",\n",
    "\"X\":\"other\",\n",
    "\"SPACE\":\"space\"}\n",
    "\n",
    "def pos_complete(dialogue):\n",
    "    address = dialogue\n",
    "    for word, initial in dictionary.items():\n",
    "        address = address.replace(word, initial)\n",
    "    return(address)\n",
    "    \n",
    "df['pos_text_complete'] = df.apply(lambda x: pos_complete(x['pos_text']), axis = 1 )\n",
    "df['pos_complete'] = df.apply(lambda x: pos_complete(x['pos_']), axis = 1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace transcription symbols with words that can be understood by pre-trained embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>pos_text</th>\n",
       "      <th>pos_</th>\n",
       "      <th>pos_text_complete</th>\n",
       "      <th>pos_complete</th>\n",
       "      <th>new_text</th>\n",
       "      <th>text_for_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, sentence, text, pos_text, pos_, pos_text_complete, pos_complete, new_text, text_for_POS]\n",
       "Index: []"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def special_tags(line):\n",
    "    line = re.sub(r'\\[\\/\\]', '[ repetition ]', line)\n",
    "    line = re.sub(r'\\[\\/\\/\\]', '[ retraction ]', line)\n",
    "    line = re.sub(r'\\(\\.\\.\\)', '[ pause ]', line)\n",
    "    line = re.sub(r'\\(\\.\\)', '[ short_pause ]', line)\n",
    "    line = re.sub(r'\\(\\.\\.\\.\\)', '[ long_pause ]', line)\n",
    "    line = re.sub(r'(\\([a-zA-Z0-9_]+\\))', ' [ incomplete_word ]', line)\n",
    "    line = re.sub(r'(\\[\\:\\s.*?\\])', '[ assimilation ]', line)   \n",
    "    line = re.sub(r'\\(', '', line) # Eliminamos parentesis izquierdos\n",
    "    line = re.sub(r'\\)', '', line)\n",
    "    line = re.sub('[<]', '', line)\n",
    "    line = re.sub('[>]', '', line)\n",
    "    line = re.sub('<', '', line)\n",
    "    line = re.sub('>', '', line)\n",
    "    line = re.sub(r'\\[\\]', '', line)\n",
    "    line = re.sub(r'\\[x\\s2\\]', '', line) # Eliminamos los [x numero]\n",
    "    line = re.sub(r'\\[x\\s3\\]', '[ repetition_repetition_repetition ]', line)\n",
    "    line = re.sub(r'\\[x\\s4\\]', '', line)\n",
    "    line = re.sub(r'\\[x\\s6\\]', '[ repetition_repetition_repetition_repetition_repetition_repetition ]', line)\n",
    "    line = re.sub(r'(\\+\\.\\.\\.)', '[ incomplete_sentence ]', line)\n",
    "    line = re.sub(r'(\\+\\.\\.\\?)', '[ incomplete_sentence ]', line)\n",
    "    line = re.sub(r'(\\[\\+\\sgram])', '[ grammatical_error ]', line) \n",
    "    #line = re.sub(r'(\\[\\+\\sgram])', r'\\[\\sgrammatical\\_error\\s\\]', line)\n",
    "    line = re.sub(r'(\\[\\+\\sjar])', '[ jargon_error ]', line)\n",
    "    line = re.sub(r'(\\[\\+\\ses])', '[ meaningless_error ]', line)\n",
    "    line = re.sub(r'(\\[\\+\\scir])', '[ circumlocution_error ]', line)\n",
    "    line = re.sub(r'(\\[\\+\\sexc])', '', line) # Elimianmos +exc (exclusion) y no contamos las ocurrencias\n",
    "    line = re.sub(r'(\\[\\*\\s.*?\\])', '[ word_error ]', line)\n",
    "    line = re.sub(r'(\\s\\+\\W.*?)', '', line)\n",
    "    line = re.sub(r'(\\s\\+\\s\\W.*?)', '', line)\n",
    "    line = re.sub(r'(\\B\\&=\\w+)', '[ action ]', line)\n",
    "    line = re.sub(r'xxx', '[ unintelligible ]', line)\n",
    "    line = re.sub(r'(\\B\\&uh)', '[ hesitation ]', line)\n",
    "    line = re.sub(r'(\\B\\&um)', '[ hesitation ]', line)\n",
    "    line = re.sub(r'(\\B\\&hm)', '[ hesitation ]', line)\n",
    "    line = re.sub(r'(\\B\\&mm)', '[ hesitation ]', line)\n",
    "    line = re.sub(r'(\\smm)', '[ hesitation ]', line)\n",
    "    line = re.sub(r'(huh)', '[ hesitation ]', line)\n",
    "    line = re.sub(r'(hum)', '[ hesitation ]', line)\n",
    "    line = re.sub(r'(hm)', '[ hesitation ]', line)\n",
    "    line = re.sub(r'(mhm)', '[ hesitation ]', line)\n",
    "    line = re.sub(r'(\\B\\&\\w+)', '[ disfluency ]', line)\n",
    "    line = re.sub(r'(\\B\\&)', '', line)\n",
    "    line = re.sub(r'(\\:)', '', line)\n",
    "    line = re.sub(r'(\\/)', '', line)\n",
    "    line = re.sub(r'(\\+)', '', line)\n",
    "    line = re.sub(r'(\\+\\s)', '', line)\n",
    "    line = re.sub(r'(\\â€¡)', '', line)\n",
    "    line = re.sub(r'(\\@\\w+)', '', line)\n",
    "    line = re.sub(r'www', '', line)\n",
    "    \n",
    "    return(line)\n",
    "  \n",
    "    \n",
    "\n",
    "df['new_text'] = df.apply(lambda x: special_tags(x['text']), axis = 1 )\n",
    "\n",
    "   \n",
    "# We generate a column without annotations in squared brackets for not skewing the POS tagging\n",
    "df['text_for_POS'] = df.apply(lambda x: re.sub(r'(\\[\\s.*?\\])', '', (x['new_text'])), axis = 1 )\n",
    "\n",
    "df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cookie_tagged.csv', index = False, sep = ';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kashgari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
