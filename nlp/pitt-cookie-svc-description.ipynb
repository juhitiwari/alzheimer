{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utterances por frase sin simbolos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitt_path = Path('../data/Pitt')\n",
    "model_path = pitt_path.parent/'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>group</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_clean</th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>['the scene is &lt;in the&gt; [/] in the kitchen . '...</td>\n",
       "      <td>['the scene is in the kitchen .', 'the mother ...</td>\n",
       "      <td>the scene is &lt;in the&gt; [/] in the kitchen .  th...</td>\n",
       "      <td>the scene is in the kitchen . the mother is wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>['oh I see the sink is running over . ', 'I se...</td>\n",
       "      <td>['oh I see the sink is running over .', 'I see...</td>\n",
       "      <td>oh I see the sink is running over .  I see the...</td>\n",
       "      <td>oh I see the sink is running over . I see the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>control</td>\n",
       "      <td>['&amp;um a boy and a girl are in the kitchen with...</td>\n",
       "      <td>['a boy and a girl are in the kitchen with the...</td>\n",
       "      <td>&amp;um a boy and a girl are in the kitchen with t...</td>\n",
       "      <td>a boy and a girl are in the kitchen with their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>control</td>\n",
       "      <td>['okay . [+ exc] ', 'it was summertime and mot...</td>\n",
       "      <td>['okay .', 'it was summertime and mother and t...</td>\n",
       "      <td>okay . [+ exc]  it was summertime and mother a...</td>\n",
       "      <td>okay . it was summertime and mother and the ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>control</td>\n",
       "      <td>['&amp;=clears:throat wait (un)til I put my glasse...</td>\n",
       "      <td>['wait until I put my glasses on .', \"oh ‡ the...</td>\n",
       "      <td>&amp;=clears:throat wait (un)til I put my glasses ...</td>\n",
       "      <td>wait until I put my glasses on . oh ‡ there's ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    group                                          sentences  \\\n",
       "0           0  control  ['the scene is <in the> [/] in the kitchen . '...   \n",
       "1           1  control  ['oh I see the sink is running over . ', 'I se...   \n",
       "2           2  control  ['&um a boy and a girl are in the kitchen with...   \n",
       "3           3  control  ['okay . [+ exc] ', 'it was summertime and mot...   \n",
       "4           4  control  ['&=clears:throat wait (un)til I put my glasse...   \n",
       "\n",
       "                                     sentences_clean  \\\n",
       "0  ['the scene is in the kitchen .', 'the mother ...   \n",
       "1  ['oh I see the sink is running over .', 'I see...   \n",
       "2  ['a boy and a girl are in the kitchen with the...   \n",
       "3  ['okay .', 'it was summertime and mother and t...   \n",
       "4  ['wait until I put my glasses on .', \"oh ‡ the...   \n",
       "\n",
       "                                                text  \\\n",
       "0  the scene is <in the> [/] in the kitchen .  th...   \n",
       "1  oh I see the sink is running over .  I see the...   \n",
       "2  &um a boy and a girl are in the kitchen with t...   \n",
       "3  okay . [+ exc]  it was summertime and mother a...   \n",
       "4  &=clears:throat wait (un)til I put my glasses ...   \n",
       "\n",
       "                                               clean  \n",
       "0  the scene is in the kitchen . the mother is wi...  \n",
       "1  oh I see the sink is running over . I see the ...  \n",
       "2  a boy and a girl are in the kitchen with their...  \n",
       "3  okay . it was summertime and mother and the ch...  \n",
       "4  wait until I put my glasses on . oh ‡ there's ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitt_df = pd.read_csv(model_path/'pitt-cookie-complete.csv')\n",
    "pitt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pitt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEXT_COL = 'clean'    # 'text' for annotated\n",
    "test_split = 0.2\n",
    "\n",
    "df = pitt_df.copy()\n",
    "\n",
    "X = df[TEXT_COL]\n",
    "y = df['group']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_split, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words / Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 1492)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/code/fast.ai/env/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        str...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('counts', CountVectorizer()),\n",
    "                     ('classifier', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46  8]\n",
      " [18 39]]\n"
     ]
    }
   ],
   "source": [
    "# Form a prediction set\n",
    "predictions = text_clf.predict(X_test)\n",
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     control       0.72      0.85      0.78        54\n",
      "    dementia       0.83      0.68      0.75        57\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       111\n",
      "   macro avg       0.77      0.77      0.76       111\n",
      "weighted avg       0.78      0.77      0.76       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7657657657657657\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 6 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    1.7s finished\n",
      "/home/pedro/code/fast.ai/env/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': [1.9], 'vect__max_features': [1000], 'vect__min_df': [50], 'vect__ngram_range': [(1, 1)], 'cls__C': (0.001, 0.0015, 0.01, 1, 10, 100), 'cls__loss': ['squared_hinge'], 'cls__max_iter': [1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[('vect', CountVectorizer()),\n",
    "                           ('cls', LinearSVC()),\n",
    "                    ])\n",
    " \n",
    "#Aqui definimos el espacio de parámetros a explorar\n",
    "parameters = {'vect__max_df': [1.9],\n",
    "              'vect__max_features': [1000],\n",
    "              'vect__min_df': [50],\n",
    "              'vect__ngram_range': [(1, 1)],\n",
    "              'cls__C': (0.001, 0.0015, 0.01, 1, 10, 100),\n",
    "              'cls__loss': ['squared_hinge'],\n",
    "              'cls__max_iter': [1000],\n",
    "            }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=parameters,\n",
    "                           scoring='roc_auc',\n",
    "                           verbose=3,\n",
    "                           n_jobs = -1,\n",
    "                           cv=20                          \n",
    "                          )\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls__C': 0.0015,\n",
       " 'cls__loss': 'squared_hinge',\n",
       " 'cls__max_iter': 1000,\n",
       " 'vect__max_df': 1.9,\n",
       " 'vect__max_features': 1000,\n",
       " 'vect__min_df': 50,\n",
       " 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.9, max_features=1000, min_df=50,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        stri...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid_search = grid_search.best_estimator_\n",
    "best_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42 12]\n",
      " [11 46]]\n"
     ]
    }
   ],
   "source": [
    "# Form a prediction set\n",
    "predictions = best_grid_search.predict(X_test)\n",
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     control       0.79      0.78      0.79        54\n",
      "    dementia       0.79      0.81      0.80        57\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       111\n",
      "   macro avg       0.79      0.79      0.79       111\n",
      "weighted avg       0.79      0.79      0.79       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7927927927927928\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547    well the little kid's falling off his stool . ...\n",
       "81     the little girl's pointing to her mouth . she ...\n",
       "140    climbing . dishwashing . pointing . stealing c...\n",
       "79     mhm . there's a boy and a girl and the boy is ...\n",
       "272    okay a child falling off a stool in the attemp...\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/models/scikit-svc-bow.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use protocol version 2 because I need to run coremltools in Python 2.7\n",
    "joblib.dump(best_grid_search, '../data/models/scikit-svc-bow.pkl', protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['control', 'control', 'control', 'control', 'dementia', 'control',\n",
       "       'dementia', 'dementia', 'control', 'dementia'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid_search.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"okay a child falling off a stool in the attempt to reach the cookie jar which it looks like he's knocked the lid off . and maybe he's gonna drop the cookie . and his girlfriend is standing there beckoning him or reaching for the cookie that he's sposta give her . and the mother is not paying any attention to the kids . she's looking out the window and drying the dishes . at the same time she has let the sink run over and the water is cascading down on the floor and onto her feet . the curtains are waving and the window is open . and the yard looks like it's manicured . and other than the stool and the cabinets and the dishes that's all I can see .\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dementia'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid_search.predict([\"theres a little boys takin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547    dementia\n",
       "81      control\n",
       "140     control\n",
       "79      control\n",
       "272    dementia\n",
       "Name: group, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.9, max_features=1000, min_df=50,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None, vocabulary=None))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, vectorizer = model.steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 2,\n",
       " 'the': 95,\n",
       " 'action': 1,\n",
       " 'okay': 67,\n",
       " 'it': 51,\n",
       " 'boy': 10,\n",
       " 'and': 3,\n",
       " 'girl': 34,\n",
       " 'well': 109,\n",
       " 'they': 98,\n",
       " 'falling': 28,\n",
       " 'down': 24,\n",
       " 'in': 48,\n",
       " 'here': 44,\n",
       " 'this': 100,\n",
       " 'water': 108,\n",
       " 'be': 8,\n",
       " 'going': 35,\n",
       " 'there': 97,\n",
       " 'but': 11,\n",
       " 'on': 68,\n",
       " 'getting': 33,\n",
       " 'something': 89,\n",
       " 'to': 101,\n",
       " 'is': 50,\n",
       " 'what': 110,\n",
       " 'that': 94,\n",
       " 'looks': 60,\n",
       " 'some': 88,\n",
       " 'like': 57,\n",
       " 'yeah': 113,\n",
       " 'reaching': 79,\n",
       " 'cookie': 13,\n",
       " 'jar': 52,\n",
       " 'stool': 92,\n",
       " 'over': 76,\n",
       " 'her': 43,\n",
       " 'hand': 39,\n",
       " 'up': 104,\n",
       " 'for': 30,\n",
       " 'cookies': 14,\n",
       " 'mother': 61,\n",
       " 'overflowing': 77,\n",
       " 'from': 31,\n",
       " 'sink': 85,\n",
       " 'she': 84,\n",
       " 'drying': 25,\n",
       " 'dishes': 20,\n",
       " 'looking': 59,\n",
       " 'out': 73,\n",
       " 'window': 111,\n",
       " 'floor': 29,\n",
       " 'curtains': 17,\n",
       " 'are': 5,\n",
       " 'you': 114,\n",
       " 'can': 12,\n",
       " 'see': 83,\n",
       " 'outside': 75,\n",
       " 'dish': 19,\n",
       " 'about': 0,\n",
       " 'fall': 27,\n",
       " 'off': 65,\n",
       " 'of': 64,\n",
       " 'washing': 107,\n",
       " 'spilling': 90,\n",
       " 'kitchen': 54,\n",
       " 'little': 58,\n",
       " 'at': 7,\n",
       " 'taking': 93,\n",
       " 'out_of': 74,\n",
       " 'think': 99,\n",
       " 'he': 42,\n",
       " 'standing': 91,\n",
       " 'handing': 40,\n",
       " 'because': 9,\n",
       " 'don': 23,\n",
       " 'want': 105,\n",
       " 'has': 41,\n",
       " 'running': 81,\n",
       " 'with': 112,\n",
       " 'two': 103,\n",
       " 'cups': 16,\n",
       " 'guess': 38,\n",
       " 'cupboard': 15,\n",
       " 'open': 71,\n",
       " 'not': 63,\n",
       " 'them': 96,\n",
       " 'one': 69,\n",
       " 'no': 62,\n",
       " 'his': 46,\n",
       " 'sister': 86,\n",
       " 'if': 47,\n",
       " 'know': 55,\n",
       " 'let': 56,\n",
       " 'onto': 70,\n",
       " 'did': 18,\n",
       " 'say': 82,\n",
       " 'trying': 102,\n",
       " 'get': 32,\n",
       " 'oh': 66,\n",
       " 'gonna': 36,\n",
       " 'anything': 4,\n",
       " 'else': 26,\n",
       " 'right': 80,\n",
       " 'got': 37,\n",
       " 'was': 106,\n",
       " 'into': 49,\n",
       " 'plate': 78,\n",
       " 'him': 45,\n",
       " 'just': 53,\n",
       " 'as': 6,\n",
       " 'do': 21,\n",
       " 'or': 72,\n",
       " 'doing': 22,\n",
       " 'so': 87}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the classifier itself and the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.0015, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, classifier = model.steps[1]\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/models/scikit-svc-bow-classifier.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use protocol version 2 because I need to run coremltools in Python 2.7\n",
    "joblib.dump(classifier, '../data/models/scikit-svc-bow-classifier.pkl', protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert vocab frequencies from int64 to number so they can be json-serialized\n",
    "vocab = vectorizer.vocabulary_\n",
    "vocab = {k: int(v) for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/models/scikit-svc-bow-vocab.txt', 'w+') as f:\n",
    "    f.write(json.dumps(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier was converted to CoreML externally - conversion doesn't work in Python3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some app results differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0,  0,  1, 11,  0,  1,  0,  1,  0,  0,  0,  0,  1,  3,  0,  0,\n",
       "          0,  1,  0,  0,  2,  0,  0,  0,  1,  1,  0,  0,  1,  1,  1,  0,\n",
       "          0,  0,  0,  0,  1,  0,  0,  0,  0,  1,  3,  2,  0,  1,  1,  0,\n",
       "          1,  0,  4,  2,  1,  0,  0,  0,  1,  2,  0,  1,  2,  1,  0,  1,\n",
       "          0,  2,  0,  1,  1,  0,  1,  1,  1,  1,  0,  0,  1,  0,  0,  1,\n",
       "          0,  0,  0,  1,  2,  1,  0,  0,  0,  0,  0,  1,  2,  0,  2, 19,\n",
       "          0,  1,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  1,  0,  0,  2,\n",
       "          0,  0,  0]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_scikit = vectorizer.transform([X_test.iloc[4]]).todense()\n",
    "vector_scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_from_app = [[0,0,1,11,0,1,0,1,0,0,0,0,1,3,0,0,0,1,0,0,2,0,0,0,1,1,0,0,1,1,1,0,0,0,0,0,1,0,0,0,0,1,0,2,0,1,1,0,1,0,4,1,1,0,0,0,1,2,0,1,2,1,0,1,0,2,0,1,1,0,1,1,1,1,0,0,1,0,0,1,0,0,0,1,1,1,0,0,0,0,0,1,2,0,1,19,0,1,0,0,0,2,0,0,0,0,0,0,1,0,0,2,0,0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From app:\n",
    "```\n",
    "[0,0,1,11,0,1,0,1,0,0,0,0,1,3,0,0,0,1,0,0,2,0,0,0,1,1,0,0,1,1,1,0,0,0,0,0,1,0,0,0,0,1,0,2,0,1,1,0,1,0,4,1,1,0,0,0,1,2,0,1,2,1,0,1,0,2,0,1,1,0,1,1,1,1,0,0,1,0,0,1,0,0,0,1,1,1,0,0,0,0,0,1,2,0,1,19,0,1,0,0,0,2,0,0,0,0,0,0,1,0,0,2,0,0,0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['control'], dtype=object)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(vector_from_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dementia'], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([X_test.iloc[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dementia'], dtype=object)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(vector_scikit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector are slightly different. In-app tokenization is wrong for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
