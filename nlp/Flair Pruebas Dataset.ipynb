{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utterances por frase con pylangacq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylangacq as pla\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "eve = pla.read_chat('./Corpus/Pitt/Control/cookie/*.cha', encoding = 'utf-8')\n",
    "tagged = eve.tagged_sents(participant='PAR')\n",
    "sentences = eve.sents(participant='PAR')\n",
    "group = list(['control']*len(tagged))\n",
    "control_df = pd.DataFrame(\n",
    "    {'utterances': sentences,\n",
    "     'tagged': tagged,\n",
    "     'group': group\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "eve = pla.read_chat('./Corpus/Pitt/Dementia/cookie/*.cha', encoding = 'utf-8')\n",
    "tagged = eve.tagged_sents(participant='PAR')\n",
    "sentences = eve.sents(participant='PAR')\n",
    "group = list(['dementia']*len(tagged))\n",
    "dementia_df = pd.DataFrame(\n",
    "    {'utterances': sentences,\n",
    "     'tagged': tagged,\n",
    "     'group': group\n",
    "    })\n",
    "#dementia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos los dos df , reorganizamos random y pasamos la colummna utterances de list -> str\n",
    "df = pd.concat([control_df, dementia_df])\n",
    "df = shuffle(df).reset_index(drop=True)\n",
    "\n",
    "utterances_str = []\n",
    "for i in range(len(df['utterances'])):\n",
    "    list1 = df['utterances'][i]\n",
    "    str1 = ' '.join(list1)\n",
    "    utterances_str.append(str1)\n",
    "    \n",
    "df['utterances_str'] = utterances_str\n",
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['group', 'utterances_str']].rename(columns={\"group\":\"label\", \"utterances_str\":\"text\"})\n",
    "\n",
    "data['label'] = '__label__' + data['label'].astype(str)\n",
    "\n",
    "data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 23:09:52,687 Reading data from .\n",
      "2019-04-16 23:09:52,688 Train: train.csv\n",
      "2019-04-16 23:09:52,689 Dev: dev.csv\n",
      "2019-04-16 23:09:52,690 Test: test.csv\n",
      "2019-04-16 23:09:53,269 this function is deprecated, use smart_open.open instead\n",
      "2019-04-16 23:09:55,032 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 23:09:55,034 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-16 23:09:55,035 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsus/anaconda3/envs/nlp_course/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 23:09:56,368 epoch 1 - iter 0/177 - loss 0.02158587\n",
      "2019-04-16 23:10:11,759 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 23:10:11,761 Exiting from training early.\n",
      "2019-04-16 23:10:11,762 Saving model ...\n",
      "2019-04-16 23:10:15,590 Done.\n",
      "2019-04-16 23:10:15,593 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 23:10:15,597 Testing using best model ...\n",
      "2019-04-16 23:10:15,600 loading file best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsus/anaconda3/envs/nlp_course/lib/python3.6/site-packages/torch/serialization.py:542: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  result = unpickler.load()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-57b58ab2ce9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, evaluation_metric, learning_rate, mini_batch_size, eval_mini_batch_size, max_epochs, anneal_factor, patience, anneal_against_train_loss, train_with_dev, monitor_train, embeddings_in_memory, checkpoint, save_final_model, anneal_with_restarts, test_mode, param_selection_mode, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# test best model if test data is present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_in_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_mini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mfinal_test\u001b[0;34m(self, base_path, embeddings_in_memory, evaluation_metric, eval_mini_batch_size)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         test_metric, test_loss = self.evaluate(self.model, self.corpus.test, eval_mini_batch_size=eval_mini_batch_size,\n\u001b[0;32m--> 278\u001b[0;31m                                                embeddings_in_memory=embeddings_in_memory)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'MICRO_AVG: acc {test_metric.micro_avg_accuracy()} - f1-score {test_metric.micro_avg_f_score()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_set, eval_mini_batch_size, embeddings_in_memory, out_path)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             return ModelTrainer._evaluate_text_classifier(model, data_set, eval_mini_batch_size, embeddings_in_memory,\n\u001b[0;32m--> 343\u001b[0;31m                                                           out_path)\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             return ModelTrainer._evaluate_sequence_tagger(model, data_set, eval_mini_batch_size, embeddings_in_memory,\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36m_evaluate_text_classifier\u001b[0;34m(model, sentences, eval_mini_batch_size, embeddings_in_memory, out_path)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_labels_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mclear_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malso_clear_word_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0membeddings_in_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36mforward_labels_and_loss\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_labels_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obtain_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtext_embedding_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;31m# first, sort sentences by number of tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;31m# get hidden states from language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mall_hidden_states_in_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_per_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# take first or last hidden states from language model as word representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mget_representation\u001b[0;34m(self, strings, chars_per_chunk)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mrnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, ordered_sequence_lengths)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_course/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "\n",
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
    "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('./', max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utterances por frase con Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_cha = './Corpus/Pitt/Control/cookie/*.cha'\n",
    "path_cha = './Corpus/Pitt/Dementia/cookie/*.cha'\n",
    "\n",
    "processed = []\n",
    "def process_with_symbols(path_cha):\n",
    "    import glob\n",
    "    import re\n",
    "    \n",
    "    files = sorted(glob.glob(path_cha))\n",
    "    \n",
    "    processed = []\n",
    "    \n",
    "    for file in files:\n",
    "        document = open(file).read()\n",
    "        doc = document.replace('\\t', ' ').split('\\n')\n",
    "        \n",
    "        \n",
    "        pre_list = []\n",
    "        for d in doc:\n",
    "            match = re.findall(r'\\*PAR:(.*)',d)\n",
    "            if (len(match) != 0):\n",
    "                pre_list.append(match)\n",
    "\n",
    "        listt = []\n",
    "        for p in pre_list:\n",
    "            match = re.sub('x15.*?x15', '', str(p))\n",
    "            match = re.sub('[\\\\\\]', '', match)\n",
    "            match = re.sub('[\"\"\"]', '', match)\n",
    "            match = re.sub('[\\\\\\']', '', match)\n",
    "            match = re.search(r'.*?\\[(.*)].*', match).group(1)\n",
    "            listt.append(match)\n",
    "        \n",
    "        processed.append(listt)\n",
    "    \n",
    "    return(processed)\n",
    "    \n",
    "\n",
    "utterances_symbol = process_with_symbols(path_cha)    \n",
    "    \n",
    "#utterances_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deshacemos la lista embebida\n",
    "#utterances_symbol_control = [item for sublist in utterances_symbol for item in sublist]\n",
    "utterances_symbol_control = utterances_symbol\n",
    "len(utterances_symbol_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deshacemos la lista embebida\n",
    "#utterances_symbol_dementia = [item for sublist in utterances_symbol for item in sublist]\n",
    "utterances_symbol_dementia = utterances_symbol\n",
    "len(utterances_symbol_dementia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = list(['control']*len(utterances_symbol_control))\n",
    "control_df = pd.DataFrame(\n",
    "    {'label': group,\n",
    "     'text': utterances_symbol_control\n",
    "     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = list(['dementia']*len(utterances_symbol_dementia))\n",
    "dementia_df = pd.DataFrame(\n",
    "    {'label': group,\n",
    "     'text': utterances_symbol_dementia\n",
    "     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos los dos df , reorganizamos random y pasamos la colummna utterances de list -> str\n",
    "df_spacy = pd.concat([control_df, dementia_df])\n",
    "df_spacy = shuffle(df_spacy).reset_index(drop=True)\n",
    "#df_spacy.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = df[['group', 'utterances_str']].rename(columns={\"group\":\"label\", \"utterances_str\":\"text\"})\n",
    "data = df_spacy\n",
    "data['label'] = '__label__' + data['label'].astype(str)\n",
    "\n",
    "data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "2019-04-16 19:48:32,384 Reading data from .\n",
      "2019-04-16 19:48:32,385 Train: train.csv\n",
      "2019-04-16 19:48:32,386 Dev: dev.csv\n",
      "2019-04-16 19:48:32,387 Test: test.csv\n",
      "2019-04-16 19:48:33,370 this function is deprecated, use smart_open.open instead\n",
      "2019-04-16 19:48:34,702 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:48:34,703 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-16 19:48:34,706 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsus/anaconda3/envs/nlp_course/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 19:48:35,225 epoch 1 - iter 0/175 - loss 0.02173432\n",
      "2019-04-16 19:48:44,904 epoch 1 - iter 17/175 - loss 0.02209040\n",
      "2019-04-16 19:48:54,585 epoch 1 - iter 34/175 - loss 0.02186388\n",
      "2019-04-16 19:49:05,845 epoch 1 - iter 51/175 - loss 0.02178764\n",
      "2019-04-16 19:49:17,049 epoch 1 - iter 68/175 - loss 0.02169157\n",
      "2019-04-16 19:49:27,428 epoch 1 - iter 85/175 - loss 0.02149766\n",
      "2019-04-16 19:49:38,461 epoch 1 - iter 102/175 - loss 0.02149710\n",
      "2019-04-16 19:49:49,386 epoch 1 - iter 119/175 - loss 0.02147310\n",
      "2019-04-16 19:50:00,122 epoch 1 - iter 136/175 - loss 0.02140294\n",
      "2019-04-16 19:50:10,759 epoch 1 - iter 153/175 - loss 0.02142385\n",
      "2019-04-16 19:50:21,705 epoch 1 - iter 170/175 - loss 0.02139754\n",
      "2019-04-16 19:50:23,879 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:50:23,879 EPOCH 1 done: loss 0.0215 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 19:50:34,255 DEV  : loss 0.02073390 - f-score 0.5788 - acc 0.4073\n",
      "2019-04-16 19:50:44,628 TEST : loss 0.02084202 - f-score 0.5983 - acc 0.4268\n",
      "2019-04-16 19:50:47,418 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:50:47,544 epoch 2 - iter 0/175 - loss 0.01977684\n",
      "2019-04-16 19:50:49,564 epoch 2 - iter 17/175 - loss 0.02122949\n",
      "2019-04-16 19:50:51,745 epoch 2 - iter 34/175 - loss 0.02098396\n",
      "2019-04-16 19:50:53,894 epoch 2 - iter 51/175 - loss 0.02094891\n",
      "2019-04-16 19:50:56,083 epoch 2 - iter 68/175 - loss 0.02094625\n",
      "2019-04-16 19:50:58,350 epoch 2 - iter 85/175 - loss 0.02084645\n",
      "2019-04-16 19:51:00,658 epoch 2 - iter 102/175 - loss 0.02085105\n",
      "2019-04-16 19:51:03,032 epoch 2 - iter 119/175 - loss 0.02080244\n",
      "2019-04-16 19:51:05,332 epoch 2 - iter 136/175 - loss 0.02076086\n",
      "2019-04-16 19:51:07,712 epoch 2 - iter 153/175 - loss 0.02072492\n",
      "2019-04-16 19:51:09,986 epoch 2 - iter 170/175 - loss 0.02073352\n",
      "2019-04-16 19:51:10,481 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:51:10,482 EPOCH 2 done: loss 0.0208 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 19:51:11,064 DEV  : loss 0.02455676 - f-score 0.5372 - acc 0.3673\n",
      "2019-04-16 19:51:11,614 TEST : loss 0.02469551 - f-score 0.5323 - acc 0.3627\n",
      "2019-04-16 19:51:16,128 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:51:16,271 epoch 3 - iter 0/175 - loss 0.02139962\n",
      "2019-04-16 19:51:18,277 epoch 3 - iter 17/175 - loss 0.02116663\n",
      "2019-04-16 19:51:20,420 epoch 3 - iter 34/175 - loss 0.02111307\n",
      "2019-04-16 19:51:22,947 epoch 3 - iter 51/175 - loss 0.02075533\n",
      "2019-04-16 19:51:25,416 epoch 3 - iter 68/175 - loss 0.02060981\n",
      "2019-04-16 19:51:27,777 epoch 3 - iter 85/175 - loss 0.02051084\n",
      "2019-04-16 19:51:30,177 epoch 3 - iter 102/175 - loss 0.02042055\n",
      "2019-04-16 19:51:32,696 epoch 3 - iter 119/175 - loss 0.02045388\n",
      "2019-04-16 19:51:35,148 epoch 3 - iter 136/175 - loss 0.02055949\n",
      "2019-04-16 19:51:37,577 epoch 3 - iter 153/175 - loss 0.02051288\n",
      "2019-04-16 19:51:40,034 epoch 3 - iter 170/175 - loss 0.02048697\n",
      "2019-04-16 19:51:40,552 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:51:40,553 EPOCH 3 done: loss 0.0206 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 19:51:41,206 DEV  : loss 0.02041553 - f-score 0.6132 - acc 0.4421\n",
      "2019-04-16 19:51:41,766 TEST : loss 0.02079084 - f-score 0.6098 - acc 0.4386\n",
      "2019-04-16 19:51:46,009 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:51:46,149 epoch 4 - iter 0/175 - loss 0.01888538\n",
      "2019-04-16 19:51:48,198 epoch 4 - iter 17/175 - loss 0.02023655\n",
      "2019-04-16 19:51:50,501 epoch 4 - iter 34/175 - loss 0.02026659\n",
      "2019-04-16 19:51:52,842 epoch 4 - iter 51/175 - loss 0.02021508\n",
      "2019-04-16 19:51:55,061 epoch 4 - iter 68/175 - loss 0.01998958\n",
      "2019-04-16 19:51:57,573 epoch 4 - iter 85/175 - loss 0.02013247\n",
      "2019-04-16 19:52:00,083 epoch 4 - iter 102/175 - loss 0.02014008\n",
      "2019-04-16 19:52:02,615 epoch 4 - iter 119/175 - loss 0.02014810\n",
      "2019-04-16 19:52:05,055 epoch 4 - iter 136/175 - loss 0.02017765\n",
      "2019-04-16 19:52:07,597 epoch 4 - iter 153/175 - loss 0.02021745\n",
      "2019-04-16 19:52:10,056 epoch 4 - iter 170/175 - loss 0.02017740\n",
      "2019-04-16 19:52:10,556 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:52:10,557 EPOCH 4 done: loss 0.0203 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 19:52:11,220 DEV  : loss 0.02010863 - f-score 0.6089 - acc 0.4377\n",
      "2019-04-16 19:52:11,807 TEST : loss 0.02034683 - f-score 0.6098 - acc 0.4386\n",
      "2019-04-16 19:52:15,975 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:52:16,142 epoch 5 - iter 0/175 - loss 0.01589725\n",
      "2019-04-16 19:52:18,209 epoch 5 - iter 17/175 - loss 0.02029133\n",
      "2019-04-16 19:52:20,721 epoch 5 - iter 34/175 - loss 0.01985341\n",
      "2019-04-16 19:52:23,185 epoch 5 - iter 51/175 - loss 0.01996680\n",
      "2019-04-16 19:52:25,595 epoch 5 - iter 68/175 - loss 0.02001555\n",
      "2019-04-16 19:52:27,936 epoch 5 - iter 85/175 - loss 0.02006855\n",
      "2019-04-16 19:52:30,315 epoch 5 - iter 102/175 - loss 0.02006865\n",
      "2019-04-16 19:52:32,761 epoch 5 - iter 119/175 - loss 0.02005947\n",
      "2019-04-16 19:52:35,251 epoch 5 - iter 136/175 - loss 0.02002676\n",
      "2019-04-16 19:52:37,551 epoch 5 - iter 153/175 - loss 0.01998484\n",
      "2019-04-16 19:52:39,781 epoch 5 - iter 170/175 - loss 0.01993770\n",
      "2019-04-16 19:52:40,213 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:52:40,214 EPOCH 5 done: loss 0.0200 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 19:52:40,850 DEV  : loss 0.02341202 - f-score 0.5559 - acc 0.3849\n",
      "2019-04-16 19:52:41,420 TEST : loss 0.02394474 - f-score 0.5395 - acc 0.3694\n",
      "2019-04-16 19:52:45,843 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:52:45,992 epoch 6 - iter 0/175 - loss 0.02512303\n",
      "2019-04-16 19:52:48,115 epoch 6 - iter 17/175 - loss 0.01977063\n",
      "2019-04-16 19:52:50,313 epoch 6 - iter 34/175 - loss 0.01949206\n",
      "2019-04-16 19:52:52,572 epoch 6 - iter 51/175 - loss 0.01973761\n",
      "2019-04-16 19:52:54,911 epoch 6 - iter 68/175 - loss 0.01981741\n",
      "2019-04-16 19:52:57,237 epoch 6 - iter 85/175 - loss 0.01989116\n",
      "2019-04-16 19:52:59,520 epoch 6 - iter 102/175 - loss 0.01986211\n",
      "2019-04-16 19:53:01,732 epoch 6 - iter 119/175 - loss 0.01992361\n",
      "2019-04-16 19:53:04,094 epoch 6 - iter 136/175 - loss 0.01995036\n",
      "2019-04-16 19:53:06,292 epoch 6 - iter 153/175 - loss 0.01994199\n",
      "2019-04-16 19:53:08,642 epoch 6 - iter 170/175 - loss 0.01993195\n",
      "2019-04-16 19:53:09,212 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:53:09,213 EPOCH 6 done: loss 0.0200 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 19:53:09,883 DEV  : loss 0.02315004 - f-score 0.5444 - acc 0.3740\n",
      "2019-04-16 19:53:10,417 TEST : loss 0.02300574 - f-score 0.5495 - acc 0.3788\n",
      "2019-04-16 19:53:14,439 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:53:14,572 epoch 7 - iter 0/175 - loss 0.02269604\n",
      "2019-04-16 19:53:16,608 epoch 7 - iter 17/175 - loss 0.01946756\n",
      "2019-04-16 19:53:18,554 epoch 7 - iter 34/175 - loss 0.01995627\n",
      "2019-04-16 19:53:20,776 epoch 7 - iter 51/175 - loss 0.01972542\n",
      "2019-04-16 19:53:22,719 epoch 7 - iter 68/175 - loss 0.01974232\n",
      "2019-04-16 19:53:24,683 epoch 7 - iter 85/175 - loss 0.01970072\n",
      "2019-04-16 19:53:26,642 epoch 7 - iter 102/175 - loss 0.01973169\n",
      "2019-04-16 19:53:28,654 epoch 7 - iter 119/175 - loss 0.01970881\n",
      "2019-04-16 19:53:30,745 epoch 7 - iter 136/175 - loss 0.01977100\n",
      "2019-04-16 19:53:32,770 epoch 7 - iter 153/175 - loss 0.01976540\n",
      "2019-04-16 19:53:34,968 epoch 7 - iter 170/175 - loss 0.01966863\n",
      "2019-04-16 19:53:35,428 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:53:35,429 EPOCH 7 done: loss 0.0198 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 19:53:36,027 DEV  : loss 0.02124149 - f-score 0.6132 - acc 0.4421\n",
      "2019-04-16 19:53:36,566 TEST : loss 0.02133409 - f-score 0.6055 - acc 0.4342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 19:53:40,352 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:53:40,498 epoch 8 - iter 0/175 - loss 0.02415928\n",
      "2019-04-16 19:53:42,453 epoch 8 - iter 17/175 - loss 0.01998995\n",
      "2019-04-16 19:53:44,485 epoch 8 - iter 34/175 - loss 0.01922567\n",
      "2019-04-16 19:53:46,867 epoch 8 - iter 51/175 - loss 0.01919771\n",
      "2019-04-16 19:53:49,056 epoch 8 - iter 68/175 - loss 0.01917967\n",
      "2019-04-16 19:53:51,367 epoch 8 - iter 85/175 - loss 0.01917253\n",
      "2019-04-16 19:53:53,730 epoch 8 - iter 102/175 - loss 0.01912282\n",
      "2019-04-16 19:53:55,918 epoch 8 - iter 119/175 - loss 0.01911164\n",
      "2019-04-16 19:53:58,134 epoch 8 - iter 136/175 - loss 0.01918013\n",
      "2019-04-16 19:54:00,239 epoch 8 - iter 153/175 - loss 0.01924460\n",
      "2019-04-16 19:54:02,411 epoch 8 - iter 170/175 - loss 0.01933487\n",
      "2019-04-16 19:54:02,880 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:54:02,881 EPOCH 8 done: loss 0.0194 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 19:54:03,482 DEV  : loss 0.02145889 - f-score 0.6017 - acc 0.4303\n",
      "2019-04-16 19:54:04,020 TEST : loss 0.02214049 - f-score 0.5839 - acc 0.4124\n",
      "2019-04-16 19:54:07,908 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:54:08,075 epoch 9 - iter 0/175 - loss 0.02181495\n",
      "2019-04-16 19:54:10,135 epoch 9 - iter 17/175 - loss 0.01948793\n",
      "2019-04-16 19:54:12,400 epoch 9 - iter 34/175 - loss 0.01935308\n",
      "2019-04-16 19:54:14,720 epoch 9 - iter 51/175 - loss 0.01940842\n",
      "2019-04-16 19:54:17,040 epoch 9 - iter 68/175 - loss 0.01939204\n",
      "2019-04-16 19:54:19,350 epoch 9 - iter 85/175 - loss 0.01938304\n",
      "2019-04-16 19:54:21,542 epoch 9 - iter 102/175 - loss 0.01930410\n",
      "2019-04-16 19:54:23,947 epoch 9 - iter 119/175 - loss 0.01934338\n",
      "2019-04-16 19:54:26,252 epoch 9 - iter 136/175 - loss 0.01934906\n",
      "2019-04-16 19:54:28,466 epoch 9 - iter 153/175 - loss 0.01937731\n",
      "2019-04-16 19:54:30,784 epoch 9 - iter 170/175 - loss 0.01931143\n",
      "2019-04-16 19:54:31,288 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:54:31,289 EPOCH 9 done: loss 0.0194 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 19:54:31,885 DEV  : loss 0.02133679 - f-score 0.5946 - acc 0.4230\n",
      "2019-04-16 19:54:32,414 TEST : loss 0.02157365 - f-score 0.5983 - acc 0.4268\n",
      "2019-04-16 19:54:32,416 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:54:32,565 epoch 10 - iter 0/175 - loss 0.02179653\n",
      "2019-04-16 19:54:34,824 epoch 10 - iter 17/175 - loss 0.01892720\n",
      "2019-04-16 19:54:37,021 epoch 10 - iter 34/175 - loss 0.01899317\n",
      "2019-04-16 19:54:39,200 epoch 10 - iter 51/175 - loss 0.01891708\n",
      "2019-04-16 19:54:41,423 epoch 10 - iter 68/175 - loss 0.01903897\n",
      "2019-04-16 19:54:43,612 epoch 10 - iter 85/175 - loss 0.01914870\n",
      "2019-04-16 19:54:45,848 epoch 10 - iter 102/175 - loss 0.01902752\n",
      "2019-04-16 19:54:47,978 epoch 10 - iter 119/175 - loss 0.01900119\n",
      "2019-04-16 19:54:50,169 epoch 10 - iter 136/175 - loss 0.01897825\n",
      "2019-04-16 19:54:52,350 epoch 10 - iter 153/175 - loss 0.01909265\n",
      "2019-04-16 19:54:54,584 epoch 10 - iter 170/175 - loss 0.01910336\n",
      "2019-04-16 19:54:55,077 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:54:55,078 EPOCH 10 done: loss 0.0192 - lr 0.1000 - bad epochs 1\n",
      "2019-04-16 19:54:55,733 DEV  : loss 0.01963861 - f-score 0.6375 - acc 0.4679\n",
      "2019-04-16 19:54:56,329 TEST : loss 0.01954334 - f-score 0.6485 - acc 0.4798\n",
      "2019-04-16 19:55:03,532 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 19:55:03,533 Testing using best model ...\n",
      "2019-04-16 19:55:03,534 loading file best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsus/anaconda3/envs/nlp_course/lib/python3.6/site-packages/torch/serialization.py:542: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  result = unpickler.load()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 19:55:05,019 MICRO_AVG: acc 0.4798 - f1-score 0.6485\n",
      "2019-04-16 19:55:05,020 MACRO_AVG: acc 0.4547 - f1-score 0.61625\n",
      "2019-04-16 19:55:05,021 control    tp: 125 - fp: 44 - fn: 201 - tn: 327 - precision: 0.7396 - recall: 0.3834 - accuracy: 0.3378 - f1-score: 0.5050\n",
      "2019-04-16 19:55:05,021 dementia   tp: 327 - fp: 201 - fn: 44 - tn: 125 - precision: 0.6193 - recall: 0.8814 - accuracy: 0.5717 - f1-score: 0.7275\n",
      "2019-04-16 19:55:05,021 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.6485,\n",
       " 'dev_score_history': [0.5788,\n",
       "  0.5372,\n",
       "  0.6132,\n",
       "  0.6089,\n",
       "  0.5559,\n",
       "  0.5444,\n",
       "  0.6132,\n",
       "  0.6017,\n",
       "  0.5946,\n",
       "  0.6375],\n",
       " 'train_loss_history': [0.021479301571503944,\n",
       "  0.02083736562959775,\n",
       "  0.020615555827039556,\n",
       "  0.020280838996129192,\n",
       "  0.02003447825845379,\n",
       "  0.020013122574841787,\n",
       "  0.01978355974301033,\n",
       "  0.019387096359021694,\n",
       "  0.019407997151016335,\n",
       "  0.019220238228140122],\n",
       " 'dev_loss_history': [0.020733904093503952,\n",
       "  0.024556757882237434,\n",
       "  0.020415527746081352,\n",
       "  0.020108630880713463,\n",
       "  0.023412024602293968,\n",
       "  0.023150039836764336,\n",
       "  0.02124148979783058,\n",
       "  0.021458886563777924,\n",
       "  0.021336788311600685,\n",
       "  0.019638612866401672]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "\n",
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
    "\n",
    "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('./', max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 20:56:03,929 Reading data from .\n",
      "2019-04-16 20:56:03,931 Train: train.csv\n",
      "2019-04-16 20:56:03,932 Dev: dev.csv\n",
      "2019-04-16 20:56:03,933 Test: test.csv\n",
      "2019-04-16 20:56:04,668 this function is deprecated, use smart_open.open instead\n",
      "2019-04-16 20:56:06,059 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 20:56:06,060 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-16 20:56:06,061 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsus/anaconda3/envs/nlp_course/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 20:56:06,788 epoch 1 - iter 0/175 - loss 0.02253088\n",
      "2019-04-16 20:56:17,509 epoch 1 - iter 17/175 - loss 0.02199896\n",
      "2019-04-16 20:56:28,634 epoch 1 - iter 34/175 - loss 0.02201932\n",
      "2019-04-16 20:56:40,735 epoch 1 - iter 51/175 - loss 0.02184712\n",
      "2019-04-16 20:56:54,415 epoch 1 - iter 68/175 - loss 0.02184557\n",
      "2019-04-16 20:57:06,901 epoch 1 - iter 85/175 - loss 0.02177826\n",
      "2019-04-16 20:57:18,612 epoch 1 - iter 102/175 - loss 0.02165912\n",
      "2019-04-16 20:57:30,091 epoch 1 - iter 119/175 - loss 0.02157411\n",
      "2019-04-16 20:57:41,496 epoch 1 - iter 136/175 - loss 0.02152725\n",
      "2019-04-16 20:57:53,007 epoch 1 - iter 153/175 - loss 0.02147225\n",
      "2019-04-16 20:58:04,720 epoch 1 - iter 170/175 - loss 0.02146622\n",
      "2019-04-16 20:58:07,403 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 20:58:07,404 EPOCH 1 done: loss 0.0215 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 20:58:19,850 DEV  : loss 0.02107741 - f-score 0.6017 - acc 0.4303\n",
      "2019-04-16 20:58:31,689 TEST : loss 0.02138332 - f-score 0.6011 - acc 0.4297\n",
      "2019-04-16 20:58:35,823 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 20:58:35,967 epoch 2 - iter 0/175 - loss 0.02082048\n",
      "2019-04-16 20:58:38,070 epoch 2 - iter 17/175 - loss 0.02113466\n",
      "2019-04-16 20:58:40,554 epoch 2 - iter 34/175 - loss 0.02100021\n",
      "2019-04-16 20:58:42,910 epoch 2 - iter 51/175 - loss 0.02088371\n",
      "2019-04-16 20:58:45,319 epoch 2 - iter 68/175 - loss 0.02101543\n",
      "2019-04-16 20:58:47,833 epoch 2 - iter 85/175 - loss 0.02097001\n",
      "2019-04-16 20:58:49,974 epoch 2 - iter 102/175 - loss 0.02070431\n",
      "2019-04-16 20:58:52,554 epoch 2 - iter 119/175 - loss 0.02068936\n",
      "2019-04-16 20:58:54,928 epoch 2 - iter 136/175 - loss 0.02074145\n",
      "2019-04-16 20:58:57,364 epoch 2 - iter 153/175 - loss 0.02074415\n",
      "2019-04-16 20:58:59,763 epoch 2 - iter 170/175 - loss 0.02080828\n",
      "2019-04-16 20:59:00,286 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 20:59:00,289 EPOCH 2 done: loss 0.0209 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 20:59:00,985 DEV  : loss 0.02083709 - f-score 0.5716 - acc 0.4002\n",
      "2019-04-16 20:59:01,608 TEST : loss 0.02095872 - f-score 0.5624 - acc 0.3912\n",
      "2019-04-16 20:59:05,521 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 20:59:05,676 epoch 3 - iter 0/175 - loss 0.02105023\n",
      "2019-04-16 20:59:07,978 epoch 3 - iter 17/175 - loss 0.02063545\n",
      "2019-04-16 20:59:10,322 epoch 3 - iter 34/175 - loss 0.02071962\n",
      "2019-04-16 20:59:12,395 epoch 3 - iter 51/175 - loss 0.02083696\n",
      "2019-04-16 20:59:14,465 epoch 3 - iter 68/175 - loss 0.02069899\n",
      "2019-04-16 20:59:16,622 epoch 3 - iter 85/175 - loss 0.02075209\n",
      "2019-04-16 20:59:19,063 epoch 3 - iter 102/175 - loss 0.02060706\n",
      "2019-04-16 20:59:21,526 epoch 3 - iter 119/175 - loss 0.02058193\n",
      "2019-04-16 20:59:23,874 epoch 3 - iter 136/175 - loss 0.02057802\n",
      "2019-04-16 20:59:26,280 epoch 3 - iter 153/175 - loss 0.02060706\n",
      "2019-04-16 20:59:28,816 epoch 3 - iter 170/175 - loss 0.02062669\n",
      "2019-04-16 20:59:29,342 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 20:59:29,343 EPOCH 3 done: loss 0.0207 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 20:59:29,978 DEV  : loss 0.02161576 - f-score 0.5702 - acc 0.3988\n",
      "2019-04-16 20:59:30,531 TEST : loss 0.02184659 - f-score 0.5739 - acc 0.4024\n",
      "2019-04-16 20:59:34,325 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 20:59:34,475 epoch 4 - iter 0/175 - loss 0.02475928\n",
      "2019-04-16 20:59:36,497 epoch 4 - iter 17/175 - loss 0.02084731\n",
      "2019-04-16 20:59:38,577 epoch 4 - iter 34/175 - loss 0.02073202\n",
      "2019-04-16 20:59:40,737 epoch 4 - iter 51/175 - loss 0.02069595\n",
      "2019-04-16 20:59:42,898 epoch 4 - iter 68/175 - loss 0.02051295\n",
      "2019-04-16 20:59:45,190 epoch 4 - iter 85/175 - loss 0.02038956\n",
      "2019-04-16 20:59:47,404 epoch 4 - iter 102/175 - loss 0.02036670\n",
      "2019-04-16 20:59:49,595 epoch 4 - iter 119/175 - loss 0.02032016\n",
      "2019-04-16 20:59:51,826 epoch 4 - iter 136/175 - loss 0.02024396\n",
      "2019-04-16 20:59:53,935 epoch 4 - iter 153/175 - loss 0.02021602\n",
      "2019-04-16 20:59:56,016 epoch 4 - iter 170/175 - loss 0.02016217\n",
      "2019-04-16 20:59:56,495 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 20:59:56,496 EPOCH 4 done: loss 0.0202 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 20:59:57,059 DEV  : loss 0.02029327 - f-score 0.6189 - acc 0.4481\n",
      "2019-04-16 20:59:57,602 TEST : loss 0.02076436 - f-score 0.6227 - acc 0.4521\n",
      "2019-04-16 21:00:01,336 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:00:01,486 epoch 5 - iter 0/175 - loss 0.02108644\n",
      "2019-04-16 21:00:03,540 epoch 5 - iter 17/175 - loss 0.02048169\n",
      "2019-04-16 21:00:05,867 epoch 5 - iter 34/175 - loss 0.02010248\n",
      "2019-04-16 21:00:08,147 epoch 5 - iter 51/175 - loss 0.02026502\n",
      "2019-04-16 21:00:10,451 epoch 5 - iter 68/175 - loss 0.02022468\n",
      "2019-04-16 21:00:12,872 epoch 5 - iter 85/175 - loss 0.02012431\n",
      "2019-04-16 21:00:15,160 epoch 5 - iter 102/175 - loss 0.02016434\n",
      "2019-04-16 21:00:17,533 epoch 5 - iter 119/175 - loss 0.02008694\n",
      "2019-04-16 21:00:19,866 epoch 5 - iter 136/175 - loss 0.02020942\n",
      "2019-04-16 21:00:22,082 epoch 5 - iter 153/175 - loss 0.02024245\n",
      "2019-04-16 21:00:24,287 epoch 5 - iter 170/175 - loss 0.02018377\n",
      "2019-04-16 21:00:24,760 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:00:24,760 EPOCH 5 done: loss 0.0203 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:00:25,356 DEV  : loss 0.02029433 - f-score 0.6175 - acc 0.4466\n",
      "2019-04-16 21:00:25,891 TEST : loss 0.02042678 - f-score 0.6069 - acc 0.4356\n",
      "2019-04-16 21:00:25,892 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:00:26,012 epoch 6 - iter 0/175 - loss 0.02138229\n",
      "2019-04-16 21:00:28,300 epoch 6 - iter 17/175 - loss 0.01977657\n",
      "2019-04-16 21:00:30,659 epoch 6 - iter 34/175 - loss 0.01970772\n",
      "2019-04-16 21:00:32,838 epoch 6 - iter 51/175 - loss 0.01970913\n",
      "2019-04-16 21:00:34,995 epoch 6 - iter 68/175 - loss 0.01964285\n",
      "2019-04-16 21:00:37,461 epoch 6 - iter 85/175 - loss 0.01968126\n",
      "2019-04-16 21:00:39,754 epoch 6 - iter 102/175 - loss 0.01963193\n",
      "2019-04-16 21:00:42,106 epoch 6 - iter 119/175 - loss 0.01973586\n",
      "2019-04-16 21:00:44,266 epoch 6 - iter 136/175 - loss 0.01972438\n",
      "2019-04-16 21:00:46,438 epoch 6 - iter 153/175 - loss 0.01967025\n",
      "2019-04-16 21:00:48,697 epoch 6 - iter 170/175 - loss 0.01977302\n",
      "2019-04-16 21:00:49,143 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:00:49,144 EPOCH 6 done: loss 0.0198 - lr 0.1000 - bad epochs 1\n",
      "2019-04-16 21:00:49,745 DEV  : loss 0.02049955 - f-score 0.6218 - acc 0.4511\n",
      "2019-04-16 21:00:50,272 TEST : loss 0.02068148 - f-score 0.6069 - acc 0.4356\n",
      "2019-04-16 21:00:53,945 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:00:54,104 epoch 7 - iter 0/175 - loss 0.01853743\n",
      "2019-04-16 21:00:56,221 epoch 7 - iter 17/175 - loss 0.01942717\n",
      "2019-04-16 21:00:58,426 epoch 7 - iter 34/175 - loss 0.01981377\n",
      "2019-04-16 21:01:00,619 epoch 7 - iter 51/175 - loss 0.01981589\n",
      "2019-04-16 21:01:02,826 epoch 7 - iter 68/175 - loss 0.01975751\n",
      "2019-04-16 21:01:05,120 epoch 7 - iter 85/175 - loss 0.01971887\n",
      "2019-04-16 21:01:07,305 epoch 7 - iter 102/175 - loss 0.01970902\n",
      "2019-04-16 21:01:09,556 epoch 7 - iter 119/175 - loss 0.01969129\n",
      "2019-04-16 21:01:11,966 epoch 7 - iter 136/175 - loss 0.01974248\n",
      "2019-04-16 21:01:14,312 epoch 7 - iter 153/175 - loss 0.01968266\n",
      "2019-04-16 21:01:16,579 epoch 7 - iter 170/175 - loss 0.01960410\n",
      "2019-04-16 21:01:17,050 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:01:17,052 EPOCH 7 done: loss 0.0197 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:01:17,662 DEV  : loss 0.01968454 - f-score 0.6562 - acc 0.4883\n",
      "2019-04-16 21:01:18,205 TEST : loss 0.01984586 - f-score 0.6542 - acc 0.4861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 21:01:21,833 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:01:21,962 epoch 8 - iter 0/175 - loss 0.02239427\n",
      "2019-04-16 21:01:24,002 epoch 8 - iter 17/175 - loss 0.01985807\n",
      "2019-04-16 21:01:26,127 epoch 8 - iter 34/175 - loss 0.01943525\n",
      "2019-04-16 21:01:28,393 epoch 8 - iter 51/175 - loss 0.01911848\n",
      "2019-04-16 21:01:30,698 epoch 8 - iter 68/175 - loss 0.01926302\n",
      "2019-04-16 21:01:32,869 epoch 8 - iter 85/175 - loss 0.01920509\n",
      "2019-04-16 21:01:35,003 epoch 8 - iter 102/175 - loss 0.01928262\n",
      "2019-04-16 21:01:37,298 epoch 8 - iter 119/175 - loss 0.01941797\n",
      "2019-04-16 21:01:39,531 epoch 8 - iter 136/175 - loss 0.01956648\n",
      "2019-04-16 21:01:41,838 epoch 8 - iter 153/175 - loss 0.01944977\n",
      "2019-04-16 21:01:44,120 epoch 8 - iter 170/175 - loss 0.01946906\n",
      "2019-04-16 21:01:44,576 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:01:44,579 EPOCH 8 done: loss 0.0195 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:01:45,189 DEV  : loss 0.01961473 - f-score 0.6461 - acc 0.4772\n",
      "2019-04-16 21:01:45,908 TEST : loss 0.01984644 - f-score 0.6585 - acc 0.4909\n",
      "2019-04-16 21:01:49,540 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:01:49,689 epoch 9 - iter 0/175 - loss 0.02058773\n",
      "2019-04-16 21:01:51,761 epoch 9 - iter 17/175 - loss 0.01919373\n",
      "2019-04-16 21:01:54,113 epoch 9 - iter 34/175 - loss 0.01914835\n",
      "2019-04-16 21:01:56,478 epoch 9 - iter 51/175 - loss 0.01899726\n",
      "2019-04-16 21:01:58,826 epoch 9 - iter 68/175 - loss 0.01902661\n",
      "2019-04-16 21:02:01,127 epoch 9 - iter 85/175 - loss 0.01899333\n",
      "2019-04-16 21:02:03,365 epoch 9 - iter 102/175 - loss 0.01910718\n",
      "2019-04-16 21:02:05,699 epoch 9 - iter 119/175 - loss 0.01926953\n",
      "2019-04-16 21:02:08,031 epoch 9 - iter 136/175 - loss 0.01930812\n",
      "2019-04-16 21:02:10,491 epoch 9 - iter 153/175 - loss 0.01926194\n",
      "2019-04-16 21:02:12,886 epoch 9 - iter 170/175 - loss 0.01926467\n",
      "2019-04-16 21:02:13,405 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:02:13,409 EPOCH 9 done: loss 0.0194 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:02:14,009 DEV  : loss 0.01935340 - f-score 0.6461 - acc 0.4772\n",
      "2019-04-16 21:02:14,549 TEST : loss 0.01928619 - f-score 0.6714 - acc 0.5054\n",
      "2019-04-16 21:02:18,071 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:02:18,205 epoch 10 - iter 0/175 - loss 0.02090078\n",
      "2019-04-16 21:02:20,300 epoch 10 - iter 17/175 - loss 0.01924764\n",
      "2019-04-16 21:02:22,717 epoch 10 - iter 34/175 - loss 0.01894984\n",
      "2019-04-16 21:02:25,212 epoch 10 - iter 51/175 - loss 0.01938723\n",
      "2019-04-16 21:02:27,703 epoch 10 - iter 68/175 - loss 0.01935701\n",
      "2019-04-16 21:02:30,129 epoch 10 - iter 85/175 - loss 0.01938289\n",
      "2019-04-16 21:02:32,322 epoch 10 - iter 102/175 - loss 0.01938563\n",
      "2019-04-16 21:02:34,386 epoch 10 - iter 119/175 - loss 0.01946823\n",
      "2019-04-16 21:02:36,449 epoch 10 - iter 136/175 - loss 0.01946385\n",
      "2019-04-16 21:02:38,540 epoch 10 - iter 153/175 - loss 0.01945741\n",
      "2019-04-16 21:02:40,648 epoch 10 - iter 170/175 - loss 0.01937800\n",
      "2019-04-16 21:02:41,099 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:02:41,100 EPOCH 10 done: loss 0.0195 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:02:41,719 DEV  : loss 0.01898688 - f-score 0.6748 - acc 0.5092\n",
      "2019-04-16 21:02:42,275 TEST : loss 0.01906816 - f-score 0.6872 - acc 0.5235\n",
      "2019-04-16 21:02:42,277 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:02:42,418 epoch 11 - iter 0/175 - loss 0.01874294\n",
      "2019-04-16 21:02:44,492 epoch 11 - iter 17/175 - loss 0.01991970\n",
      "2019-04-16 21:02:46,652 epoch 11 - iter 34/175 - loss 0.01951744\n",
      "2019-04-16 21:02:48,828 epoch 11 - iter 51/175 - loss 0.01947087\n",
      "2019-04-16 21:02:50,935 epoch 11 - iter 68/175 - loss 0.01932345\n",
      "2019-04-16 21:02:52,990 epoch 11 - iter 85/175 - loss 0.01943624\n",
      "2019-04-16 21:02:55,181 epoch 11 - iter 102/175 - loss 0.01948142\n",
      "2019-04-16 21:02:57,629 epoch 11 - iter 119/175 - loss 0.01951297\n",
      "2019-04-16 21:03:00,081 epoch 11 - iter 136/175 - loss 0.01931459\n",
      "2019-04-16 21:03:02,312 epoch 11 - iter 153/175 - loss 0.01931709\n",
      "2019-04-16 21:03:04,663 epoch 11 - iter 170/175 - loss 0.01924351\n",
      "2019-04-16 21:03:05,171 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:03:05,172 EPOCH 11 done: loss 0.0193 - lr 0.1000 - bad epochs 1\n",
      "2019-04-16 21:03:05,806 DEV  : loss 0.01896857 - f-score 0.6762 - acc 0.5108\n",
      "2019-04-16 21:03:06,406 TEST : loss 0.01910226 - f-score 0.6700 - acc 0.5038\n",
      "2019-04-16 21:03:10,409 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:03:10,554 epoch 12 - iter 0/175 - loss 0.01567364\n",
      "2019-04-16 21:03:12,461 epoch 12 - iter 17/175 - loss 0.02011706\n",
      "2019-04-16 21:03:14,729 epoch 12 - iter 34/175 - loss 0.01987921\n",
      "2019-04-16 21:03:16,799 epoch 12 - iter 51/175 - loss 0.01970021\n",
      "2019-04-16 21:03:18,896 epoch 12 - iter 68/175 - loss 0.01962078\n",
      "2019-04-16 21:03:20,982 epoch 12 - iter 85/175 - loss 0.01931897\n",
      "2019-04-16 21:03:23,085 epoch 12 - iter 102/175 - loss 0.01939658\n",
      "2019-04-16 21:03:25,246 epoch 12 - iter 119/175 - loss 0.01933983\n",
      "2019-04-16 21:03:27,506 epoch 12 - iter 136/175 - loss 0.01930148\n",
      "2019-04-16 21:03:29,705 epoch 12 - iter 153/175 - loss 0.01925344\n",
      "2019-04-16 21:03:31,901 epoch 12 - iter 170/175 - loss 0.01920514\n",
      "2019-04-16 21:03:32,411 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:03:32,414 EPOCH 12 done: loss 0.0193 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:03:33,119 DEV  : loss 0.02153872 - f-score 0.6103 - acc 0.4392\n",
      "2019-04-16 21:03:33,803 TEST : loss 0.02220117 - f-score 0.5983 - acc 0.4268\n",
      "2019-04-16 21:03:37,882 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:03:38,018 epoch 13 - iter 0/175 - loss 0.02303988\n",
      "2019-04-16 21:03:40,250 epoch 13 - iter 17/175 - loss 0.01902813\n",
      "2019-04-16 21:03:42,668 epoch 13 - iter 34/175 - loss 0.01895704\n",
      "2019-04-16 21:03:45,195 epoch 13 - iter 51/175 - loss 0.01902136\n",
      "2019-04-16 21:03:47,614 epoch 13 - iter 68/175 - loss 0.01887787\n",
      "2019-04-16 21:03:49,888 epoch 13 - iter 85/175 - loss 0.01895983\n",
      "2019-04-16 21:03:52,153 epoch 13 - iter 102/175 - loss 0.01888849\n",
      "2019-04-16 21:03:54,250 epoch 13 - iter 119/175 - loss 0.01883563\n",
      "2019-04-16 21:03:56,456 epoch 13 - iter 136/175 - loss 0.01899124\n",
      "2019-04-16 21:03:58,793 epoch 13 - iter 153/175 - loss 0.01899377\n",
      "2019-04-16 21:04:01,085 epoch 13 - iter 170/175 - loss 0.01900008\n",
      "2019-04-16 21:04:01,586 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:04:01,590 EPOCH 13 done: loss 0.0192 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:04:02,218 DEV  : loss 0.02206737 - f-score 0.5688 - acc 0.3974\n",
      "2019-04-16 21:04:02,770 TEST : loss 0.02231523 - f-score 0.5552 - acc 0.3843\n",
      "2019-04-16 21:04:06,504 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:04:06,656 epoch 14 - iter 0/175 - loss 0.02574525\n",
      "2019-04-16 21:04:08,733 epoch 14 - iter 17/175 - loss 0.01865226\n",
      "2019-04-16 21:04:11,030 epoch 14 - iter 34/175 - loss 0.01862229\n",
      "2019-04-16 21:04:13,417 epoch 14 - iter 51/175 - loss 0.01892334\n",
      "2019-04-16 21:04:15,775 epoch 14 - iter 68/175 - loss 0.01898187\n",
      "2019-04-16 21:04:18,117 epoch 14 - iter 85/175 - loss 0.01892611\n",
      "2019-04-16 21:04:20,354 epoch 14 - iter 102/175 - loss 0.01891552\n",
      "2019-04-16 21:04:22,588 epoch 14 - iter 119/175 - loss 0.01890730\n",
      "2019-04-16 21:04:24,832 epoch 14 - iter 136/175 - loss 0.01887812\n",
      "2019-04-16 21:04:27,036 epoch 14 - iter 153/175 - loss 0.01886263\n",
      "2019-04-16 21:04:29,282 epoch 14 - iter 170/175 - loss 0.01892887\n",
      "2019-04-16 21:04:29,761 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:04:29,763 EPOCH 14 done: loss 0.0190 - lr 0.1000 - bad epochs 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 21:04:30,371 DEV  : loss 0.01947201 - f-score 0.6562 - acc 0.4883\n",
      "2019-04-16 21:04:30,905 TEST : loss 0.01964689 - f-score 0.6643 - acc 0.4973\n",
      "2019-04-16 21:04:34,600 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:04:34,756 epoch 15 - iter 0/175 - loss 0.01722806\n",
      "2019-04-16 21:04:36,813 epoch 15 - iter 17/175 - loss 0.01786978\n",
      "2019-04-16 21:04:38,973 epoch 15 - iter 34/175 - loss 0.01844243\n",
      "2019-04-16 21:04:41,321 epoch 15 - iter 51/175 - loss 0.01886955\n",
      "2019-04-16 21:04:43,632 epoch 15 - iter 68/175 - loss 0.01870378\n",
      "2019-04-16 21:04:45,816 epoch 15 - iter 85/175 - loss 0.01880593\n",
      "2019-04-16 21:04:48,035 epoch 15 - iter 102/175 - loss 0.01889807\n",
      "2019-04-16 21:04:50,558 epoch 15 - iter 119/175 - loss 0.01890585\n",
      "2019-04-16 21:04:52,701 epoch 15 - iter 136/175 - loss 0.01886367\n",
      "2019-04-16 21:04:54,816 epoch 15 - iter 153/175 - loss 0.01891219\n",
      "2019-04-16 21:04:56,951 epoch 15 - iter 170/175 - loss 0.01884147\n",
      "2019-04-16 21:04:57,398 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:04:57,401 EPOCH 15 done: loss 0.0189 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:04:57,990 DEV  : loss 0.02319364 - f-score 0.5874 - acc 0.4158\n",
      "2019-04-16 21:04:58,535 TEST : loss 0.02289898 - f-score 0.5796 - acc 0.4081\n",
      "2019-04-16 21:05:02,120 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:05:02,267 epoch 16 - iter 0/175 - loss 0.02023079\n",
      "2019-04-16 21:05:04,353 epoch 16 - iter 17/175 - loss 0.01842176\n",
      "2019-04-16 21:05:06,544 epoch 16 - iter 34/175 - loss 0.01832142\n",
      "2019-04-16 21:05:08,769 epoch 16 - iter 51/175 - loss 0.01833783\n",
      "2019-04-16 21:05:10,924 epoch 16 - iter 68/175 - loss 0.01836431\n",
      "2019-04-16 21:05:13,081 epoch 16 - iter 85/175 - loss 0.01860247\n",
      "2019-04-16 21:05:15,283 epoch 16 - iter 102/175 - loss 0.01854748\n",
      "2019-04-16 21:05:17,425 epoch 16 - iter 119/175 - loss 0.01860129\n",
      "2019-04-16 21:05:19,684 epoch 16 - iter 136/175 - loss 0.01869428\n",
      "2019-04-16 21:05:21,937 epoch 16 - iter 153/175 - loss 0.01866562\n",
      "2019-04-16 21:05:24,331 epoch 16 - iter 170/175 - loss 0.01875052\n",
      "2019-04-16 21:05:24,909 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:05:24,912 EPOCH 16 done: loss 0.0188 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:05:25,543 DEV  : loss 0.01953472 - f-score 0.6648 - acc 0.4979\n",
      "2019-04-16 21:05:26,102 TEST : loss 0.01933645 - f-score 0.6944 - acc 0.5319\n",
      "2019-04-16 21:05:29,797 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:05:29,930 epoch 17 - iter 0/175 - loss 0.02048212\n",
      "2019-04-16 21:05:31,940 epoch 17 - iter 17/175 - loss 0.01806692\n",
      "2019-04-16 21:05:34,132 epoch 17 - iter 34/175 - loss 0.01828741\n",
      "2019-04-16 21:05:36,358 epoch 17 - iter 51/175 - loss 0.01831642\n",
      "2019-04-16 21:05:38,677 epoch 17 - iter 68/175 - loss 0.01843818\n",
      "2019-04-16 21:05:40,935 epoch 17 - iter 85/175 - loss 0.01845239\n",
      "2019-04-16 21:05:43,088 epoch 17 - iter 102/175 - loss 0.01851274\n",
      "2019-04-16 21:05:45,238 epoch 17 - iter 119/175 - loss 0.01867077\n",
      "2019-04-16 21:05:47,592 epoch 17 - iter 136/175 - loss 0.01860554\n",
      "2019-04-16 21:05:49,948 epoch 17 - iter 153/175 - loss 0.01865569\n",
      "2019-04-16 21:05:52,264 epoch 17 - iter 170/175 - loss 0.01868276\n",
      "2019-04-16 21:05:52,706 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:05:52,708 EPOCH 17 done: loss 0.0187 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:05:53,298 DEV  : loss 0.02326516 - f-score 0.6017 - acc 0.4303\n",
      "2019-04-16 21:05:53,829 TEST : loss 0.02264284 - f-score 0.6270 - acc 0.4566\n",
      "2019-04-16 21:05:57,983 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:05:58,134 epoch 18 - iter 0/175 - loss 0.02609473\n",
      "2019-04-16 21:06:00,040 epoch 18 - iter 17/175 - loss 0.01952939\n",
      "2019-04-16 21:06:02,132 epoch 18 - iter 34/175 - loss 0.01867291\n",
      "2019-04-16 21:06:04,395 epoch 18 - iter 51/175 - loss 0.01864241\n",
      "2019-04-16 21:06:06,807 epoch 18 - iter 68/175 - loss 0.01850372\n",
      "2019-04-16 21:06:09,191 epoch 18 - iter 85/175 - loss 0.01856879\n",
      "2019-04-16 21:06:11,474 epoch 18 - iter 102/175 - loss 0.01862749\n",
      "2019-04-16 21:06:13,676 epoch 18 - iter 119/175 - loss 0.01867503\n",
      "2019-04-16 21:06:15,826 epoch 18 - iter 136/175 - loss 0.01864683\n",
      "2019-04-16 21:06:17,989 epoch 18 - iter 153/175 - loss 0.01868159\n",
      "2019-04-16 21:06:20,190 epoch 18 - iter 170/175 - loss 0.01868871\n",
      "2019-04-16 21:06:20,674 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:06:20,675 EPOCH 18 done: loss 0.0188 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:06:21,275 DEV  : loss 0.02129275 - f-score 0.5745 - acc 0.4030\n",
      "2019-04-16 21:06:21,807 TEST : loss 0.02096663 - f-score 0.5839 - acc 0.4124\n",
      "2019-04-16 21:06:21,809 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:06:21,954 epoch 19 - iter 0/175 - loss 0.01863067\n",
      "2019-04-16 21:06:24,301 epoch 19 - iter 17/175 - loss 0.01873149\n",
      "2019-04-16 21:06:26,432 epoch 19 - iter 34/175 - loss 0.01885685\n",
      "2019-04-16 21:06:28,557 epoch 19 - iter 51/175 - loss 0.01887550\n",
      "2019-04-16 21:06:30,800 epoch 19 - iter 68/175 - loss 0.01870507\n",
      "2019-04-16 21:06:33,030 epoch 19 - iter 85/175 - loss 0.01879097\n",
      "2019-04-16 21:06:35,262 epoch 19 - iter 102/175 - loss 0.01862743\n",
      "2019-04-16 21:06:37,654 epoch 19 - iter 119/175 - loss 0.01866125\n",
      "2019-04-16 21:06:40,027 epoch 19 - iter 136/175 - loss 0.01860156\n",
      "2019-04-16 21:06:42,405 epoch 19 - iter 153/175 - loss 0.01850569\n",
      "2019-04-16 21:06:44,664 epoch 19 - iter 170/175 - loss 0.01859982\n",
      "2019-04-16 21:06:45,128 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:06:45,132 EPOCH 19 done: loss 0.0187 - lr 0.1000 - bad epochs 1\n",
      "2019-04-16 21:06:45,726 DEV  : loss 0.01921433 - f-score 0.6748 - acc 0.5092\n",
      "2019-04-16 21:06:46,263 TEST : loss 0.01905604 - f-score 0.6714 - acc 0.5054\n",
      "2019-04-16 21:06:49,917 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:06:50,063 epoch 20 - iter 0/175 - loss 0.01370795\n",
      "2019-04-16 21:06:51,935 epoch 20 - iter 17/175 - loss 0.01823068\n",
      "2019-04-16 21:06:53,903 epoch 20 - iter 34/175 - loss 0.01831658\n",
      "2019-04-16 21:06:56,062 epoch 20 - iter 51/175 - loss 0.01859370\n",
      "2019-04-16 21:06:58,164 epoch 20 - iter 68/175 - loss 0.01871959\n",
      "2019-04-16 21:07:00,644 epoch 20 - iter 85/175 - loss 0.01887525\n",
      "2019-04-16 21:07:03,105 epoch 20 - iter 102/175 - loss 0.01862394\n",
      "2019-04-16 21:07:05,372 epoch 20 - iter 119/175 - loss 0.01859564\n",
      "2019-04-16 21:07:07,811 epoch 20 - iter 136/175 - loss 0.01836505\n",
      "2019-04-16 21:07:10,329 epoch 20 - iter 153/175 - loss 0.01841832\n",
      "2019-04-16 21:07:13,039 epoch 20 - iter 170/175 - loss 0.01845852\n",
      "2019-04-16 21:07:13,500 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:07:13,503 EPOCH 20 done: loss 0.0186 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 21:07:14,142 DEV  : loss 0.02012119 - f-score 0.6433 - acc 0.4741\n",
      "2019-04-16 21:07:14,736 TEST : loss 0.01972844 - f-score 0.6614 - acc 0.4941\n",
      "2019-04-16 21:07:22,659 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 21:07:22,662 Testing using best model ...\n",
      "2019-04-16 21:07:22,664 loading file best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsus/anaconda3/envs/nlp_course/lib/python3.6/site-packages/torch/serialization.py:542: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  result = unpickler.load()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 21:07:24,615 MICRO_AVG: acc 0.4941 - f1-score 0.6614\n",
      "2019-04-16 21:07:24,616 MACRO_AVG: acc 0.4729 - f1-score 0.6351\n",
      "2019-04-16 21:07:24,617 control    tp: 137 - fp: 47 - fn: 189 - tn: 324 - precision: 0.7446 - recall: 0.4202 - accuracy: 0.3673 - f1-score: 0.5372\n",
      "2019-04-16 21:07:24,617 dementia   tp: 324 - fp: 189 - fn: 47 - tn: 137 - precision: 0.6316 - recall: 0.8733 - accuracy: 0.5786 - f1-score: 0.7330\n",
      "2019-04-16 21:07:24,618 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.6614,\n",
       " 'dev_score_history': [0.6017,\n",
       "  0.5716,\n",
       "  0.5702,\n",
       "  0.6189,\n",
       "  0.6175,\n",
       "  0.6218,\n",
       "  0.6562,\n",
       "  0.6461,\n",
       "  0.6461,\n",
       "  0.6748,\n",
       "  0.6762,\n",
       "  0.6103,\n",
       "  0.5688,\n",
       "  0.6562,\n",
       "  0.5874,\n",
       "  0.6648,\n",
       "  0.6017,\n",
       "  0.5745,\n",
       "  0.6748,\n",
       "  0.6433],\n",
       " 'train_loss_history': [0.021528136054617775,\n",
       "  0.020918723131654254,\n",
       "  0.020671948106422314,\n",
       "  0.02021780730875869,\n",
       "  0.020267455465824397,\n",
       "  0.019829929500305158,\n",
       "  0.019733682093096942,\n",
       "  0.01954431365774557,\n",
       "  0.019386975915095042,\n",
       "  0.019476833241528043,\n",
       "  0.019304383225429007,\n",
       "  0.01926900947217962,\n",
       "  0.019165536268497985,\n",
       "  0.01903738566758472,\n",
       "  0.018929886339042586,\n",
       "  0.018756284930314362,\n",
       "  0.01872031389063537,\n",
       "  0.018818035534712643,\n",
       "  0.018686705716542226,\n",
       "  0.01857208439724859],\n",
       " 'dev_loss_history': [0.021077409386634827,\n",
       "  0.020837094634771347,\n",
       "  0.021615762263536453,\n",
       "  0.02029326930642128,\n",
       "  0.020294327288866043,\n",
       "  0.020499547943472862,\n",
       "  0.01968453638255596,\n",
       "  0.019614726305007935,\n",
       "  0.01935340091586113,\n",
       "  0.018986878916621208,\n",
       "  0.018968569114804268,\n",
       "  0.021538719534873962,\n",
       "  0.022067369893193245,\n",
       "  0.01947200670838356,\n",
       "  0.023193640634417534,\n",
       "  0.019534721970558167,\n",
       "  0.023265158757567406,\n",
       "  0.021292749792337418,\n",
       "  0.019214332103729248,\n",
       "  0.020121188834309578]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "\n",
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
    "\n",
    "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('./', max_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utterances por dialogo con Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 22:21:11,892 Reading data from .\n",
      "2019-04-16 22:21:11,893 Train: train.csv\n",
      "2019-04-16 22:21:11,895 Dev: dev.csv\n",
      "2019-04-16 22:21:11,895 Test: test.csv\n",
      "2019-04-16 22:21:12,685 this function is deprecated, use smart_open.open instead\n",
      "2019-04-16 22:21:14,086 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:21:14,086 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-16 22:21:14,088 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsus/anaconda3/envs/nlp_course/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 22:21:23,810 epoch 1 - iter 0/14 - loss 0.02370303\n",
      "2019-04-16 22:21:37,920 epoch 1 - iter 1/14 - loss 0.02253457\n",
      "2019-04-16 22:21:56,927 epoch 1 - iter 2/14 - loss 0.02221656\n",
      "2019-04-16 22:22:12,869 epoch 1 - iter 3/14 - loss 0.02214558\n",
      "2019-04-16 22:22:27,988 epoch 1 - iter 4/14 - loss 0.02189174\n",
      "2019-04-16 22:22:38,407 epoch 1 - iter 5/14 - loss 0.02189414\n",
      "2019-04-16 22:22:53,815 epoch 1 - iter 6/14 - loss 0.02172773\n",
      "2019-04-16 22:23:09,900 epoch 1 - iter 7/14 - loss 0.02159470\n",
      "2019-04-16 22:23:24,051 epoch 1 - iter 8/14 - loss 0.02207519\n",
      "2019-04-16 22:23:41,541 epoch 1 - iter 9/14 - loss 0.02242262\n",
      "2019-04-16 22:23:58,224 epoch 1 - iter 10/14 - loss 0.02200032\n",
      "2019-04-16 22:24:12,067 epoch 1 - iter 11/14 - loss 0.02223844\n",
      "2019-04-16 22:24:24,743 epoch 1 - iter 12/14 - loss 0.02216936\n",
      "2019-04-16 22:24:35,611 epoch 1 - iter 13/14 - loss 0.02241316\n",
      "2019-04-16 22:24:35,630 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:24:35,633 EPOCH 1 done: loss 0.0224 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 22:25:03,447 DEV  : loss 0.02477421 - f-score 0.5179 - acc 0.3494\n",
      "2019-04-16 22:25:24,123 TEST : loss 0.02457215 - f-score 0.6182 - acc 0.4474\n",
      "2019-04-16 22:25:28,472 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:25:33,326 epoch 2 - iter 0/14 - loss 0.02198351\n",
      "2019-04-16 22:25:38,088 epoch 2 - iter 1/14 - loss 0.02251143\n",
      "2019-04-16 22:25:43,476 epoch 2 - iter 2/14 - loss 0.02264626\n",
      "2019-04-16 22:25:51,130 epoch 2 - iter 3/14 - loss 0.02199019\n",
      "2019-04-16 22:25:57,202 epoch 2 - iter 4/14 - loss 0.02150232\n",
      "2019-04-16 22:26:01,893 epoch 2 - iter 5/14 - loss 0.02176269\n",
      "2019-04-16 22:26:08,435 epoch 2 - iter 6/14 - loss 0.02160052\n",
      "2019-04-16 22:26:15,790 epoch 2 - iter 7/14 - loss 0.02172073\n",
      "2019-04-16 22:26:22,563 epoch 2 - iter 8/14 - loss 0.02180213\n",
      "2019-04-16 22:26:28,523 epoch 2 - iter 9/14 - loss 0.02201370\n",
      "2019-04-16 22:26:35,454 epoch 2 - iter 10/14 - loss 0.02196464\n",
      "2019-04-16 22:26:43,923 epoch 2 - iter 11/14 - loss 0.02167630\n",
      "2019-04-16 22:26:48,684 epoch 2 - iter 12/14 - loss 0.02158721\n",
      "2019-04-16 22:26:53,321 epoch 2 - iter 13/14 - loss 0.02195467\n",
      "2019-04-16 22:26:53,340 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:26:53,343 EPOCH 2 done: loss 0.0220 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 22:26:54,465 DEV  : loss 0.02522547 - f-score 0.5000 - acc 0.3333\n",
      "2019-04-16 22:26:55,254 TEST : loss 0.02581893 - f-score 0.4545 - acc 0.2941\n",
      "2019-04-16 22:26:59,388 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:27:04,149 epoch 3 - iter 0/14 - loss 0.01999506\n",
      "2019-04-16 22:27:09,137 epoch 3 - iter 1/14 - loss 0.02130123\n",
      "2019-04-16 22:27:16,293 epoch 3 - iter 2/14 - loss 0.02142965\n",
      "2019-04-16 22:27:22,142 epoch 3 - iter 3/14 - loss 0.02107208\n",
      "2019-04-16 22:27:29,947 epoch 3 - iter 4/14 - loss 0.02108008\n",
      "2019-04-16 22:27:35,538 epoch 3 - iter 5/14 - loss 0.02106394\n",
      "2019-04-16 22:27:41,549 epoch 3 - iter 6/14 - loss 0.02120275\n",
      "2019-04-16 22:27:47,397 epoch 3 - iter 7/14 - loss 0.02144557\n",
      "2019-04-16 22:27:53,811 epoch 3 - iter 8/14 - loss 0.02139201\n",
      "2019-04-16 22:28:01,112 epoch 3 - iter 9/14 - loss 0.02151804\n",
      "2019-04-16 22:28:07,532 epoch 3 - iter 10/14 - loss 0.02141364\n",
      "2019-04-16 22:28:13,392 epoch 3 - iter 11/14 - loss 0.02132146\n",
      "2019-04-16 22:28:20,049 epoch 3 - iter 12/14 - loss 0.02149225\n",
      "2019-04-16 22:28:24,538 epoch 3 - iter 13/14 - loss 0.02162018\n",
      "2019-04-16 22:28:24,551 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:28:24,554 EPOCH 3 done: loss 0.0216 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 22:28:25,667 DEV  : loss 0.02656552 - f-score 0.5000 - acc 0.3333\n",
      "2019-04-16 22:28:26,444 TEST : loss 0.02774308 - f-score 0.4545 - acc 0.2941\n",
      "2019-04-16 22:28:30,676 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:28:37,537 epoch 4 - iter 0/14 - loss 0.02199801\n",
      "2019-04-16 22:28:43,172 epoch 4 - iter 1/14 - loss 0.02172633\n",
      "2019-04-16 22:28:47,834 epoch 4 - iter 2/14 - loss 0.02137149\n",
      "2019-04-16 22:28:53,027 epoch 4 - iter 3/14 - loss 0.02121705\n",
      "2019-04-16 22:29:00,163 epoch 4 - iter 4/14 - loss 0.02120214\n",
      "2019-04-16 22:29:06,754 epoch 4 - iter 5/14 - loss 0.02121409\n",
      "2019-04-16 22:29:13,296 epoch 4 - iter 6/14 - loss 0.02112082\n",
      "2019-04-16 22:29:20,766 epoch 4 - iter 7/14 - loss 0.02107545\n",
      "2019-04-16 22:29:26,853 epoch 4 - iter 8/14 - loss 0.02110428\n",
      "2019-04-16 22:29:34,218 epoch 4 - iter 9/14 - loss 0.02120943\n",
      "2019-04-16 22:29:40,385 epoch 4 - iter 10/14 - loss 0.02127423\n",
      "2019-04-16 22:29:47,999 epoch 4 - iter 11/14 - loss 0.02124306\n",
      "2019-04-16 22:29:54,875 epoch 4 - iter 12/14 - loss 0.02114142\n",
      "2019-04-16 22:29:59,838 epoch 4 - iter 13/14 - loss 0.02127554\n",
      "2019-04-16 22:29:59,850 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:29:59,852 EPOCH 4 done: loss 0.0213 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 22:30:01,006 DEV  : loss 0.02986637 - f-score 0.5000 - acc 0.3333\n",
      "2019-04-16 22:30:01,800 TEST : loss 0.03191962 - f-score 0.4545 - acc 0.2941\n",
      "2019-04-16 22:30:06,339 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:30:12,463 epoch 5 - iter 0/14 - loss 0.02372749\n",
      "2019-04-16 22:30:19,617 epoch 5 - iter 1/14 - loss 0.02107959\n",
      "2019-04-16 22:30:25,962 epoch 5 - iter 2/14 - loss 0.02158098\n",
      "2019-04-16 22:30:29,826 epoch 5 - iter 3/14 - loss 0.02132348\n",
      "2019-04-16 22:30:38,137 epoch 5 - iter 4/14 - loss 0.02112538\n",
      "2019-04-16 22:30:43,143 epoch 5 - iter 5/14 - loss 0.02137297\n",
      "2019-04-16 22:30:50,277 epoch 5 - iter 6/14 - loss 0.02152980\n",
      "2019-04-16 22:30:55,217 epoch 5 - iter 7/14 - loss 0.02141245\n",
      "2019-04-16 22:30:59,015 epoch 5 - iter 8/14 - loss 0.02150248\n",
      "2019-04-16 22:31:03,254 epoch 5 - iter 9/14 - loss 0.02137422\n",
      "2019-04-16 22:31:09,401 epoch 5 - iter 10/14 - loss 0.02142575\n",
      "2019-04-16 22:31:15,858 epoch 5 - iter 11/14 - loss 0.02140047\n",
      "2019-04-16 22:31:23,111 epoch 5 - iter 12/14 - loss 0.02139281\n",
      "2019-04-16 22:31:29,259 epoch 5 - iter 13/14 - loss 0.02179551\n",
      "2019-04-16 22:31:29,269 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:31:29,270 EPOCH 5 done: loss 0.0218 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 22:31:30,427 DEV  : loss 0.02462201 - f-score 0.5893 - acc 0.4177\n",
      "2019-04-16 22:31:31,219 TEST : loss 0.02465370 - f-score 0.6545 - acc 0.4865\n",
      "2019-04-16 22:31:31,221 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:31:37,198 epoch 6 - iter 0/14 - loss 0.02173330\n",
      "2019-04-16 22:31:44,481 epoch 6 - iter 1/14 - loss 0.02175455\n",
      "2019-04-16 22:31:48,679 epoch 6 - iter 2/14 - loss 0.02143199\n",
      "2019-04-16 22:31:54,307 epoch 6 - iter 3/14 - loss 0.02168167\n",
      "2019-04-16 22:31:59,176 epoch 6 - iter 4/14 - loss 0.02190074\n",
      "2019-04-16 22:32:05,960 epoch 6 - iter 5/14 - loss 0.02146834\n",
      "2019-04-16 22:32:12,201 epoch 6 - iter 6/14 - loss 0.02128057\n",
      "2019-04-16 22:32:18,194 epoch 6 - iter 7/14 - loss 0.02129219\n",
      "2019-04-16 22:32:24,478 epoch 6 - iter 8/14 - loss 0.02131999\n",
      "2019-04-16 22:32:31,086 epoch 6 - iter 9/14 - loss 0.02147321\n",
      "2019-04-16 22:32:38,459 epoch 6 - iter 10/14 - loss 0.02144070\n",
      "2019-04-16 22:32:45,380 epoch 6 - iter 11/14 - loss 0.02120808\n",
      "2019-04-16 22:32:51,194 epoch 6 - iter 12/14 - loss 0.02163495\n",
      "2019-04-16 22:32:56,379 epoch 6 - iter 13/14 - loss 0.02193630\n",
      "2019-04-16 22:32:56,390 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:32:56,396 EPOCH 6 done: loss 0.0219 - lr 0.1000 - bad epochs 1\n",
      "2019-04-16 22:32:57,602 DEV  : loss 0.02458988 - f-score 0.5714 - acc 0.4000\n",
      "2019-04-16 22:32:58,415 TEST : loss 0.02458555 - f-score 0.6727 - acc 0.5068\n",
      "2019-04-16 22:32:58,417 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:33:04,542 epoch 7 - iter 0/14 - loss 0.02165130\n",
      "2019-04-16 22:33:11,805 epoch 7 - iter 1/14 - loss 0.02182506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 22:33:17,454 epoch 7 - iter 2/14 - loss 0.02137995\n",
      "2019-04-16 22:33:26,023 epoch 7 - iter 3/14 - loss 0.02090790\n",
      "2019-04-16 22:33:32,639 epoch 7 - iter 4/14 - loss 0.02097820\n",
      "2019-04-16 22:33:39,211 epoch 7 - iter 5/14 - loss 0.02082480\n",
      "2019-04-16 22:33:46,779 epoch 7 - iter 6/14 - loss 0.02121409\n",
      "2019-04-16 22:33:53,370 epoch 7 - iter 7/14 - loss 0.02139490\n",
      "2019-04-16 22:34:00,411 epoch 7 - iter 8/14 - loss 0.02104731\n",
      "2019-04-16 22:34:06,011 epoch 7 - iter 9/14 - loss 0.02136488\n",
      "2019-04-16 22:34:12,279 epoch 7 - iter 10/14 - loss 0.02133534\n",
      "2019-04-16 22:34:18,007 epoch 7 - iter 11/14 - loss 0.02129730\n",
      "2019-04-16 22:34:24,936 epoch 7 - iter 12/14 - loss 0.02126488\n",
      "2019-04-16 22:34:30,063 epoch 7 - iter 13/14 - loss 0.02153050\n",
      "2019-04-16 22:34:30,077 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:34:30,080 EPOCH 7 done: loss 0.0215 - lr 0.1000 - bad epochs 2\n",
      "2019-04-16 22:34:31,240 DEV  : loss 0.02444947 - f-score 0.5357 - acc 0.3659\n",
      "2019-04-16 22:34:32,027 TEST : loss 0.02397077 - f-score 0.6909 - acc 0.5278\n",
      "2019-04-16 22:34:32,030 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:34:37,984 epoch 8 - iter 0/14 - loss 0.02117013\n",
      "2019-04-16 22:34:43,980 epoch 8 - iter 1/14 - loss 0.02118425\n",
      "2019-04-16 22:34:49,362 epoch 8 - iter 2/14 - loss 0.02110566\n",
      "2019-04-16 22:34:55,364 epoch 8 - iter 3/14 - loss 0.02092226\n",
      "2019-04-16 22:35:02,277 epoch 8 - iter 4/14 - loss 0.02088607\n",
      "2019-04-16 22:35:07,599 epoch 8 - iter 5/14 - loss 0.02094455\n",
      "2019-04-16 22:35:14,360 epoch 8 - iter 6/14 - loss 0.02090229\n",
      "2019-04-16 22:35:21,560 epoch 8 - iter 7/14 - loss 0.02078616\n",
      "2019-04-16 22:35:27,431 epoch 8 - iter 8/14 - loss 0.02075675\n",
      "2019-04-16 22:35:34,544 epoch 8 - iter 9/14 - loss 0.02082210\n",
      "2019-04-16 22:35:41,458 epoch 8 - iter 10/14 - loss 0.02068777\n",
      "2019-04-16 22:35:47,391 epoch 8 - iter 11/14 - loss 0.02072171\n",
      "2019-04-16 22:35:52,106 epoch 8 - iter 12/14 - loss 0.02078180\n",
      "2019-04-16 22:35:57,323 epoch 8 - iter 13/14 - loss 0.02102424\n",
      "2019-04-16 22:35:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:35:57,340 EPOCH 8 done: loss 0.0210 - lr 0.1000 - bad epochs 3\n",
      "2019-04-16 22:35:58,485 DEV  : loss 0.02439291 - f-score 0.5893 - acc 0.4177\n",
      "2019-04-16 22:35:59,265 TEST : loss 0.02404804 - f-score 0.6909 - acc 0.5278\n",
      "2019-04-16 22:36:03,508 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:36:08,833 epoch 9 - iter 0/14 - loss 0.02076050\n",
      "2019-04-16 22:36:14,866 epoch 9 - iter 1/14 - loss 0.01974819\n",
      "2019-04-16 22:36:20,211 epoch 9 - iter 2/14 - loss 0.02101553\n",
      "2019-04-16 22:36:26,699 epoch 9 - iter 3/14 - loss 0.02110401\n",
      "2019-04-16 22:36:32,306 epoch 9 - iter 4/14 - loss 0.02087266\n",
      "2019-04-16 22:36:38,221 epoch 9 - iter 5/14 - loss 0.02045506\n",
      "2019-04-16 22:36:45,899 epoch 9 - iter 6/14 - loss 0.02066856\n",
      "2019-04-16 22:36:53,357 epoch 9 - iter 7/14 - loss 0.02074372\n",
      "2019-04-16 22:36:59,406 epoch 9 - iter 8/14 - loss 0.02077870\n",
      "2019-04-16 22:37:06,223 epoch 9 - iter 9/14 - loss 0.02104383\n",
      "2019-04-16 22:37:12,943 epoch 9 - iter 10/14 - loss 0.02101643\n",
      "2019-04-16 22:37:19,423 epoch 9 - iter 11/14 - loss 0.02104142\n",
      "2019-04-16 22:37:27,151 epoch 9 - iter 12/14 - loss 0.02094861\n",
      "2019-04-16 22:37:31,312 epoch 9 - iter 13/14 - loss 0.02149351\n",
      "2019-04-16 22:37:31,326 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:37:31,329 EPOCH 9 done: loss 0.0215 - lr 0.1000 - bad epochs 0\n",
      "2019-04-16 22:37:32,801 DEV  : loss 0.02485605 - f-score 0.5357 - acc 0.3659\n",
      "2019-04-16 22:37:33,667 TEST : loss 0.02375077 - f-score 0.5636 - acc 0.3924\n",
      "2019-04-16 22:37:33,669 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:37:41,284 epoch 10 - iter 0/14 - loss 0.02464448\n",
      "2019-04-16 22:37:47,973 epoch 10 - iter 1/14 - loss 0.02244083\n",
      "2019-04-16 22:37:53,276 epoch 10 - iter 2/14 - loss 0.02170317\n",
      "2019-04-16 22:38:00,586 epoch 10 - iter 3/14 - loss 0.02143615\n",
      "2019-04-16 22:38:07,744 epoch 10 - iter 4/14 - loss 0.02121029\n",
      "2019-04-16 22:38:14,171 epoch 10 - iter 5/14 - loss 0.02106988\n",
      "2019-04-16 22:38:19,913 epoch 10 - iter 6/14 - loss 0.02096884\n",
      "2019-04-16 22:38:26,505 epoch 10 - iter 7/14 - loss 0.02072169\n",
      "2019-04-16 22:38:32,497 epoch 10 - iter 8/14 - loss 0.02102449\n",
      "2019-04-16 22:38:37,917 epoch 10 - iter 9/14 - loss 0.02103041\n",
      "2019-04-16 22:38:43,528 epoch 10 - iter 10/14 - loss 0.02114613\n",
      "2019-04-16 22:38:51,214 epoch 10 - iter 11/14 - loss 0.02120559\n",
      "2019-04-16 22:38:58,371 epoch 10 - iter 12/14 - loss 0.02108273\n",
      "2019-04-16 22:39:02,419 epoch 10 - iter 13/14 - loss 0.02155823\n",
      "2019-04-16 22:39:02,439 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:39:02,440 EPOCH 10 done: loss 0.0216 - lr 0.1000 - bad epochs 1\n",
      "2019-04-16 22:39:03,518 DEV  : loss 0.02417688 - f-score 0.6071 - acc 0.4359\n",
      "2019-04-16 22:39:04,362 TEST : loss 0.02384816 - f-score 0.6727 - acc 0.5068\n",
      "2019-04-16 22:39:04,364 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:39:10,132 epoch 11 - iter 0/14 - loss 0.02018815\n",
      "2019-04-16 22:39:14,483 epoch 11 - iter 1/14 - loss 0.02047811\n",
      "2019-04-16 22:39:20,617 epoch 11 - iter 2/14 - loss 0.02107082\n",
      "2019-04-16 22:39:26,809 epoch 11 - iter 3/14 - loss 0.02102878\n",
      "2019-04-16 22:39:33,566 epoch 11 - iter 4/14 - loss 0.02089048\n",
      "2019-04-16 22:39:40,216 epoch 11 - iter 5/14 - loss 0.02065955\n",
      "2019-04-16 22:39:46,404 epoch 11 - iter 6/14 - loss 0.02183941\n",
      "2019-04-16 22:39:52,898 epoch 11 - iter 7/14 - loss 0.02218261\n",
      "2019-04-16 22:39:59,593 epoch 11 - iter 8/14 - loss 0.02202229\n",
      "2019-04-16 22:40:05,621 epoch 11 - iter 9/14 - loss 0.02202926\n",
      "2019-04-16 22:40:11,037 epoch 11 - iter 10/14 - loss 0.02183434\n",
      "2019-04-16 22:40:17,460 epoch 11 - iter 11/14 - loss 0.02161869\n",
      "2019-04-16 22:40:25,045 epoch 11 - iter 12/14 - loss 0.02145428\n",
      "2019-04-16 22:40:30,387 epoch 11 - iter 13/14 - loss 0.02163666\n",
      "2019-04-16 22:40:30,398 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:40:30,399 EPOCH 11 done: loss 0.0216 - lr 0.1000 - bad epochs 2\n",
      "2019-04-16 22:40:31,511 DEV  : loss 0.02537746 - f-score 0.5000 - acc 0.3333\n",
      "2019-04-16 22:40:32,278 TEST : loss 0.02603438 - f-score 0.4545 - acc 0.2941\n",
      "2019-04-16 22:40:32,280 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:40:38,117 epoch 12 - iter 0/14 - loss 0.02025368\n",
      "2019-04-16 22:40:44,035 epoch 12 - iter 1/14 - loss 0.02055326\n",
      "2019-04-16 22:40:48,623 epoch 12 - iter 2/14 - loss 0.02067441\n",
      "2019-04-16 22:40:55,272 epoch 12 - iter 3/14 - loss 0.02087029\n",
      "2019-04-16 22:41:02,394 epoch 12 - iter 4/14 - loss 0.02044527\n",
      "2019-04-16 22:41:08,317 epoch 12 - iter 5/14 - loss 0.02032302\n",
      "2019-04-16 22:41:14,177 epoch 12 - iter 6/14 - loss 0.02041849\n",
      "2019-04-16 22:41:20,707 epoch 12 - iter 7/14 - loss 0.02053914\n",
      "2019-04-16 22:41:27,962 epoch 12 - iter 8/14 - loss 0.02069262\n",
      "2019-04-16 22:41:34,566 epoch 12 - iter 9/14 - loss 0.02066179\n",
      "2019-04-16 22:41:40,840 epoch 12 - iter 10/14 - loss 0.02066921\n",
      "2019-04-16 22:41:47,733 epoch 12 - iter 11/14 - loss 0.02059373\n",
      "2019-04-16 22:41:55,657 epoch 12 - iter 12/14 - loss 0.02071023\n",
      "2019-04-16 22:42:01,397 epoch 12 - iter 13/14 - loss 0.02105163\n",
      "2019-04-16 22:42:01,412 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:42:01,413 EPOCH 12 done: loss 0.0211 - lr 0.1000 - bad epochs 3\n",
      "2019-04-16 22:42:02,649 DEV  : loss 0.02431145 - f-score 0.6250 - acc 0.4545\n",
      "2019-04-16 22:42:03,504 TEST : loss 0.02423236 - f-score 0.6727 - acc 0.5068\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-04-16 22:42:03,506 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:42:09,510 epoch 13 - iter 0/14 - loss 0.02034860\n",
      "2019-04-16 22:42:15,237 epoch 13 - iter 1/14 - loss 0.02054461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 22:42:21,667 epoch 13 - iter 2/14 - loss 0.02046368\n",
      "2019-04-16 22:42:27,405 epoch 13 - iter 3/14 - loss 0.02084701\n",
      "2019-04-16 22:42:34,966 epoch 13 - iter 4/14 - loss 0.02060765\n",
      "2019-04-16 22:42:42,526 epoch 13 - iter 5/14 - loss 0.02094290\n",
      "2019-04-16 22:42:49,851 epoch 13 - iter 6/14 - loss 0.02097185\n",
      "2019-04-16 22:42:53,940 epoch 13 - iter 7/14 - loss 0.02094358\n",
      "2019-04-16 22:43:00,285 epoch 13 - iter 8/14 - loss 0.02077139\n",
      "2019-04-16 22:43:06,914 epoch 13 - iter 9/14 - loss 0.02070013\n",
      "2019-04-16 22:43:13,834 epoch 13 - iter 10/14 - loss 0.02062144\n",
      "2019-04-16 22:43:20,072 epoch 13 - iter 11/14 - loss 0.02070774\n",
      "2019-04-16 22:43:26,741 epoch 13 - iter 12/14 - loss 0.02052631\n",
      "2019-04-16 22:43:30,910 epoch 13 - iter 13/14 - loss 0.02076079\n",
      "2019-04-16 22:43:30,923 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:43:30,925 EPOCH 13 done: loss 0.0208 - lr 0.0500 - bad epochs 0\n",
      "2019-04-16 22:43:32,042 DEV  : loss 0.02586518 - f-score 0.5000 - acc 0.3333\n",
      "2019-04-16 22:43:32,885 TEST : loss 0.02667178 - f-score 0.4545 - acc 0.2941\n",
      "2019-04-16 22:43:36,684 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:43:40,136 epoch 14 - iter 0/14 - loss 0.02006960\n",
      "2019-04-16 22:43:44,368 epoch 14 - iter 1/14 - loss 0.02067719\n",
      "2019-04-16 22:43:51,403 epoch 14 - iter 2/14 - loss 0.02075109\n",
      "2019-04-16 22:43:57,574 epoch 14 - iter 3/14 - loss 0.02063165\n",
      "2019-04-16 22:44:03,207 epoch 14 - iter 4/14 - loss 0.02100052\n",
      "2019-04-16 22:44:09,036 epoch 14 - iter 5/14 - loss 0.02085782\n",
      "2019-04-16 22:44:16,051 epoch 14 - iter 6/14 - loss 0.02078628\n",
      "2019-04-16 22:44:22,606 epoch 14 - iter 7/14 - loss 0.02088060\n",
      "2019-04-16 22:44:29,443 epoch 14 - iter 8/14 - loss 0.02086124\n",
      "2019-04-16 22:44:35,339 epoch 14 - iter 9/14 - loss 0.02060375\n",
      "2019-04-16 22:44:42,027 epoch 14 - iter 10/14 - loss 0.02029561\n",
      "2019-04-16 22:44:49,329 epoch 14 - iter 11/14 - loss 0.02061122\n",
      "2019-04-16 22:44:55,822 epoch 14 - iter 12/14 - loss 0.02047759\n",
      "2019-04-16 22:45:01,508 epoch 14 - iter 13/14 - loss 0.02078322\n",
      "2019-04-16 22:45:01,519 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:45:01,522 EPOCH 14 done: loss 0.0208 - lr 0.0500 - bad epochs 0\n",
      "2019-04-16 22:45:02,712 DEV  : loss 0.02454466 - f-score 0.5893 - acc 0.4177\n",
      "2019-04-16 22:45:03,635 TEST : loss 0.02455645 - f-score 0.5636 - acc 0.3924\n",
      "2019-04-16 22:45:03,637 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:45:10,353 epoch 15 - iter 0/14 - loss 0.01920405\n",
      "2019-04-16 22:45:16,641 epoch 15 - iter 1/14 - loss 0.02030793\n",
      "2019-04-16 22:45:22,383 epoch 15 - iter 2/14 - loss 0.02066015\n",
      "2019-04-16 22:45:28,559 epoch 15 - iter 3/14 - loss 0.02048841\n",
      "2019-04-16 22:45:37,022 epoch 15 - iter 4/14 - loss 0.02057939\n",
      "2019-04-16 22:45:43,901 epoch 15 - iter 5/14 - loss 0.02036387\n",
      "2019-04-16 22:45:52,217 epoch 15 - iter 6/14 - loss 0.02022862\n",
      "2019-04-16 22:45:58,639 epoch 15 - iter 7/14 - loss 0.02003729\n",
      "2019-04-16 22:46:06,193 epoch 15 - iter 8/14 - loss 0.01994877\n",
      "2019-04-16 22:46:11,957 epoch 15 - iter 9/14 - loss 0.02021408\n",
      "2019-04-16 22:46:17,043 epoch 15 - iter 10/14 - loss 0.02034468\n",
      "2019-04-16 22:46:22,176 epoch 15 - iter 11/14 - loss 0.02028168\n",
      "2019-04-16 22:46:28,574 epoch 15 - iter 12/14 - loss 0.02030919\n",
      "2019-04-16 22:46:33,300 epoch 15 - iter 13/14 - loss 0.02050526\n",
      "2019-04-16 22:46:33,314 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:46:33,322 EPOCH 15 done: loss 0.0205 - lr 0.0500 - bad epochs 1\n",
      "2019-04-16 22:46:34,476 DEV  : loss 0.02437527 - f-score 0.6071 - acc 0.4359\n",
      "2019-04-16 22:46:35,309 TEST : loss 0.02415057 - f-score 0.6727 - acc 0.5068\n",
      "2019-04-16 22:46:39,213 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:46:45,526 epoch 16 - iter 0/14 - loss 0.01791666\n",
      "2019-04-16 22:46:52,060 epoch 16 - iter 1/14 - loss 0.01877779\n",
      "2019-04-16 22:46:57,362 epoch 16 - iter 2/14 - loss 0.01889604\n",
      "2019-04-16 22:47:04,798 epoch 16 - iter 3/14 - loss 0.02025447\n",
      "2019-04-16 22:47:11,706 epoch 16 - iter 4/14 - loss 0.02038912\n",
      "2019-04-16 22:47:18,096 epoch 16 - iter 5/14 - loss 0.02053430\n",
      "2019-04-16 22:47:24,347 epoch 16 - iter 6/14 - loss 0.02063833\n",
      "2019-04-16 22:47:30,222 epoch 16 - iter 7/14 - loss 0.02059148\n",
      "2019-04-16 22:47:36,231 epoch 16 - iter 8/14 - loss 0.02058981\n",
      "2019-04-16 22:47:42,881 epoch 16 - iter 9/14 - loss 0.02052908\n",
      "2019-04-16 22:47:49,009 epoch 16 - iter 10/14 - loss 0.02046646\n",
      "2019-04-16 22:47:54,970 epoch 16 - iter 11/14 - loss 0.02057134\n",
      "2019-04-16 22:48:01,773 epoch 16 - iter 12/14 - loss 0.02059343\n",
      "2019-04-16 22:48:05,086 epoch 16 - iter 13/14 - loss 0.02083072\n",
      "2019-04-16 22:48:05,099 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:48:05,103 EPOCH 16 done: loss 0.0208 - lr 0.0500 - bad epochs 0\n",
      "2019-04-16 22:48:06,250 DEV  : loss 0.02474794 - f-score 0.5536 - acc 0.3827\n",
      "2019-04-16 22:48:07,027 TEST : loss 0.02492877 - f-score 0.5091 - acc 0.3415\n",
      "2019-04-16 22:48:07,029 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:48:12,586 epoch 17 - iter 0/14 - loss 0.01902394\n",
      "2019-04-16 22:48:18,020 epoch 17 - iter 1/14 - loss 0.01946440\n",
      "2019-04-16 22:48:23,528 epoch 17 - iter 2/14 - loss 0.01927133\n",
      "2019-04-16 22:48:30,185 epoch 17 - iter 3/14 - loss 0.01958978\n",
      "2019-04-16 22:48:37,531 epoch 17 - iter 4/14 - loss 0.01987502\n",
      "2019-04-16 22:48:43,355 epoch 17 - iter 5/14 - loss 0.02015967\n",
      "2019-04-16 22:48:49,794 epoch 17 - iter 6/14 - loss 0.02015019\n",
      "2019-04-16 22:48:55,558 epoch 17 - iter 7/14 - loss 0.02015992\n",
      "2019-04-16 22:49:01,777 epoch 17 - iter 8/14 - loss 0.02005014\n",
      "2019-04-16 22:49:09,155 epoch 17 - iter 9/14 - loss 0.02004522\n",
      "2019-04-16 22:49:15,296 epoch 17 - iter 10/14 - loss 0.02016265\n",
      "2019-04-16 22:49:20,852 epoch 17 - iter 11/14 - loss 0.02026321\n",
      "2019-04-16 22:49:29,012 epoch 17 - iter 12/14 - loss 0.02020987\n",
      "2019-04-16 22:49:34,159 epoch 17 - iter 13/14 - loss 0.02054590\n",
      "2019-04-16 22:49:34,170 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:49:34,171 EPOCH 17 done: loss 0.0205 - lr 0.0500 - bad epochs 1\n",
      "2019-04-16 22:49:35,336 DEV  : loss 0.02409437 - f-score 0.6071 - acc 0.4359\n",
      "2019-04-16 22:49:36,136 TEST : loss 0.02334849 - f-score 0.6909 - acc 0.5278\n",
      "2019-04-16 22:49:36,139 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:49:42,391 epoch 18 - iter 0/14 - loss 0.02005668\n",
      "2019-04-16 22:49:47,577 epoch 18 - iter 1/14 - loss 0.02043035\n",
      "2019-04-16 22:49:52,992 epoch 18 - iter 2/14 - loss 0.02065961\n",
      "2019-04-16 22:50:00,843 epoch 18 - iter 3/14 - loss 0.02052813\n",
      "2019-04-16 22:50:08,601 epoch 18 - iter 4/14 - loss 0.02062390\n",
      "2019-04-16 22:50:15,430 epoch 18 - iter 5/14 - loss 0.02041681\n",
      "2019-04-16 22:50:22,050 epoch 18 - iter 6/14 - loss 0.02022553\n",
      "2019-04-16 22:50:29,744 epoch 18 - iter 7/14 - loss 0.01998787\n",
      "2019-04-16 22:50:37,419 epoch 18 - iter 8/14 - loss 0.01993572\n",
      "2019-04-16 22:50:44,424 epoch 18 - iter 9/14 - loss 0.01987145\n",
      "2019-04-16 22:50:50,782 epoch 18 - iter 10/14 - loss 0.01987668\n",
      "2019-04-16 22:50:53,872 epoch 18 - iter 11/14 - loss 0.01991206\n",
      "2019-04-16 22:50:59,352 epoch 18 - iter 12/14 - loss 0.01995734\n",
      "2019-04-16 22:51:04,743 epoch 18 - iter 13/14 - loss 0.02040424\n",
      "2019-04-16 22:51:04,754 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:51:04,759 EPOCH 18 done: loss 0.0204 - lr 0.0500 - bad epochs 2\n",
      "2019-04-16 22:51:05,903 DEV  : loss 0.02487837 - f-score 0.5179 - acc 0.3494\n",
      "2019-04-16 22:51:06,670 TEST : loss 0.02514150 - f-score 0.4909 - acc 0.3253\n",
      "2019-04-16 22:51:10,344 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:51:16,655 epoch 19 - iter 0/14 - loss 0.02144414\n",
      "2019-04-16 22:51:21,819 epoch 19 - iter 1/14 - loss 0.02066529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 22:51:27,371 epoch 19 - iter 2/14 - loss 0.02040735\n",
      "2019-04-16 22:51:34,451 epoch 19 - iter 3/14 - loss 0.02039956\n",
      "2019-04-16 22:51:41,538 epoch 19 - iter 4/14 - loss 0.02057913\n",
      "2019-04-16 22:51:48,158 epoch 19 - iter 5/14 - loss 0.02043684\n",
      "2019-04-16 22:51:53,768 epoch 19 - iter 6/14 - loss 0.02016216\n",
      "2019-04-16 22:52:01,149 epoch 19 - iter 7/14 - loss 0.02037770\n",
      "2019-04-16 22:52:06,696 epoch 19 - iter 8/14 - loss 0.02050842\n",
      "2019-04-16 22:52:12,289 epoch 19 - iter 9/14 - loss 0.02044515\n",
      "2019-04-16 22:52:17,241 epoch 19 - iter 10/14 - loss 0.02046256\n",
      "2019-04-16 22:52:23,782 epoch 19 - iter 11/14 - loss 0.02048911\n",
      "2019-04-16 22:52:30,568 epoch 19 - iter 12/14 - loss 0.02045103\n",
      "2019-04-16 22:52:34,394 epoch 19 - iter 13/14 - loss 0.02073349\n",
      "2019-04-16 22:52:34,410 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:52:34,411 EPOCH 19 done: loss 0.0207 - lr 0.0500 - bad epochs 0\n",
      "2019-04-16 22:52:35,534 DEV  : loss 0.02582415 - f-score 0.5000 - acc 0.3333\n",
      "2019-04-16 22:52:36,330 TEST : loss 0.02655363 - f-score 0.4545 - acc 0.2941\n",
      "2019-04-16 22:52:36,332 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:52:42,647 epoch 20 - iter 0/14 - loss 0.01889967\n",
      "2019-04-16 22:52:47,669 epoch 20 - iter 1/14 - loss 0.01979374\n",
      "2019-04-16 22:52:53,120 epoch 20 - iter 2/14 - loss 0.01984235\n",
      "2019-04-16 22:52:59,861 epoch 20 - iter 3/14 - loss 0.01995228\n",
      "2019-04-16 22:53:07,627 epoch 20 - iter 4/14 - loss 0.01955021\n",
      "2019-04-16 22:53:14,177 epoch 20 - iter 5/14 - loss 0.01977581\n",
      "2019-04-16 22:53:20,235 epoch 20 - iter 6/14 - loss 0.01995985\n",
      "2019-04-16 22:53:25,073 epoch 20 - iter 7/14 - loss 0.02004004\n",
      "2019-04-16 22:53:31,772 epoch 20 - iter 8/14 - loss 0.01994198\n",
      "2019-04-16 22:53:39,572 epoch 20 - iter 9/14 - loss 0.01977611\n",
      "2019-04-16 22:53:45,006 epoch 20 - iter 10/14 - loss 0.01981310\n",
      "2019-04-16 22:53:50,565 epoch 20 - iter 11/14 - loss 0.01987294\n",
      "2019-04-16 22:53:57,343 epoch 20 - iter 12/14 - loss 0.02000154\n",
      "2019-04-16 22:54:02,678 epoch 20 - iter 13/14 - loss 0.02035361\n",
      "2019-04-16 22:54:02,690 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:54:02,692 EPOCH 20 done: loss 0.0204 - lr 0.0500 - bad epochs 1\n",
      "2019-04-16 22:54:03,893 DEV  : loss 0.02414840 - f-score 0.5714 - acc 0.4000\n",
      "2019-04-16 22:54:04,726 TEST : loss 0.02374180 - f-score 0.6727 - acc 0.5068\n",
      "2019-04-16 22:54:13,305 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-16 22:54:13,307 Testing using best model ...\n",
      "2019-04-16 22:54:13,312 loading file best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsus/anaconda3/envs/nlp_course/lib/python3.6/site-packages/torch/serialization.py:542: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  result = unpickler.load()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 22:54:15,773 MICRO_AVG: acc 0.5068 - f1-score 0.6727\n",
      "2019-04-16 22:54:15,774 MACRO_AVG: acc 0.5023 - f1-score 0.66735\n",
      "2019-04-16 22:54:15,776 control    tp: 15 - fp: 3 - fn: 15 - tn: 22 - precision: 0.8333 - recall: 0.5000 - accuracy: 0.4545 - f1-score: 0.6250\n",
      "2019-04-16 22:54:15,779 dementia   tp: 22 - fp: 15 - fn: 3 - tn: 15 - precision: 0.5946 - recall: 0.8800 - accuracy: 0.5500 - f1-score: 0.7097\n",
      "2019-04-16 22:54:15,781 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.6727,\n",
       " 'dev_score_history': [0.5179,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5893,\n",
       "  0.5714,\n",
       "  0.5357,\n",
       "  0.5893,\n",
       "  0.5357,\n",
       "  0.6071,\n",
       "  0.5,\n",
       "  0.625,\n",
       "  0.5,\n",
       "  0.5893,\n",
       "  0.6071,\n",
       "  0.5536,\n",
       "  0.6071,\n",
       "  0.5179,\n",
       "  0.5,\n",
       "  0.5714],\n",
       " 'train_loss_history': [0.0224131595791062,\n",
       "  0.02195466889275445,\n",
       "  0.021620179520172325,\n",
       "  0.021275544788291394,\n",
       "  0.02179550921835867,\n",
       "  0.0219363022823723,\n",
       "  0.02153050129105445,\n",
       "  0.021024236603388712,\n",
       "  0.021493510729601595,\n",
       "  0.0215582278580352,\n",
       "  0.02163666094782131,\n",
       "  0.021051625275557814,\n",
       "  0.02076079029074602,\n",
       "  0.020783218396764225,\n",
       "  0.02050525747459221,\n",
       "  0.020830724109597756,\n",
       "  0.020545900814116946,\n",
       "  0.02040423760338435,\n",
       "  0.020733493525965683,\n",
       "  0.020353614878492292],\n",
       " 'dev_loss_history': [0.02477421425282955,\n",
       "  0.02522546984255314,\n",
       "  0.02656552381813526,\n",
       "  0.02986636757850647,\n",
       "  0.024622010067105293,\n",
       "  0.02458987571299076,\n",
       "  0.02444946952164173,\n",
       "  0.024392906576395035,\n",
       "  0.024856051430106163,\n",
       "  0.02417687512934208,\n",
       "  0.025377456098794937,\n",
       "  0.024311449378728867,\n",
       "  0.02586517669260502,\n",
       "  0.02454466000199318,\n",
       "  0.024375269189476967,\n",
       "  0.0247479435056448,\n",
       "  0.024094369262456894,\n",
       "  0.02487836591899395,\n",
       "  0.025824153795838356,\n",
       "  0.024148404598236084]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "\n",
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
    "\n",
    "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('./', max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
